{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "import glob, os\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, make_scorer, average_precision_score\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.utils import resample\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = os.getcwd()\n",
    "os.chdir(basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_channels(channelsdf, nchannels=2):\n",
    "    \n",
    "    list_of_rows = [list(row) for row in channelsdf.values]\n",
    "    \n",
    "    channel_score_dict = {}\n",
    "    for i, elem in enumerate(list_of_rows[0]):\n",
    "        channel_score_dict[elem] = i\n",
    "\n",
    "    for row, rowlist in enumerate(list_of_rows[1:]):\n",
    "        for i, elem in enumerate(rowlist):\n",
    "            channel_score_dict[elem] = channel_score_dict[elem] + i\n",
    "\n",
    "    sorted_channels = sorted(channel_score_dict, key=channel_score_dict.get)\n",
    "    best_channels = sorted_channels[:nchannels]\n",
    "    \n",
    "    return best_channels\n",
    "\n",
    "def get_expression(channels):\n",
    "    expression = 'df['\n",
    "    for channel in channels:\n",
    "        expression +='(df[\\'channel\\'] == \\'' + channel + '\\')|'\n",
    "    return expression[:-1] + ']'\n",
    "\n",
    "def split_train_test(data, test_ratio):\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_set = data.iloc[:test_set_size]\n",
    "    train_set = data.iloc[test_set_size:]\n",
    "    return train_set, test_set\n",
    "\n",
    "def split_proportional(dataframe, test_ratio, target):\n",
    "    dataframe = dataframe.sample(frac=1)\n",
    "    df_seizures = dataframe[dataframe[target] == True]\n",
    "    df_normal = dataframe[dataframe[target] == False]\n",
    "    # Reduce the size of the normal dataset to obtain the same number of samples for each class\n",
    "    df_normal_downsampled = resample(df_normal, replace=True, n_samples=df_seizures.shape[0]*4, random_state=123)\n",
    "\n",
    "    train_seizures, test_seizures = split_train_test(df_seizures, test_ratio)\n",
    "    train_normal, test_normal = split_train_test(df_normal_downsampled, test_ratio)\n",
    "    \n",
    "    df_train = pd.concat([train_normal, train_seizures], axis=0)\n",
    "    df_train = df_train.sample(frac=1)\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    x_train, y_train = df_train[df_train.columns.difference([target])], df_train[target]\n",
    "    sme = SMOTEENN(random_state=42)\n",
    "    x_train_res, y_train_res = sme.fit_resample(x_train, y_train)\n",
    "    \n",
    "    df_test = pd.concat([test_normal, test_seizures], axis=0)\n",
    "    df_test = df_test.sample(frac=1)\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "    x_test, y_test = df_test[df_test.columns.difference([target])], df_test[target]\n",
    "    \n",
    "    return x_train_res, y_train_res, x_test, y_test\n",
    "\n",
    "def train_random_forest(x_train, y_train):\n",
    "    # Define simple pipeline\n",
    "    pipe_rnf = Pipeline((\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"clf\", RandomForestClassifier())\n",
    "    ))\n",
    "    # Establish params\n",
    "    param_grid = [\n",
    "                 {'clf__n_estimators': [50, 100, 200, 300, 400, 500], 'clf__max_leaf_nodes': [4,8,16,32,64]}]\n",
    "\n",
    "    model = GridSearchCV(estimator=pipe_rnf,param_grid=param_grid, cv = 5, scoring=make_scorer(roc_auc_score), return_train_score=True, n_jobs = -1)\n",
    "    model.fit(x_train, y_train)\n",
    "    return model\n",
    "\n",
    "def train_knn(x_train, y_train):\n",
    "    # Define simple pipeline\n",
    "    pipe_svc = Pipeline((\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"clf\", KNeighborsClassifier())\n",
    "    ))\n",
    "\n",
    "    param_grid = [{'clf__n_neighbors': list(range(11)), 'clf__p': [1,2], 'clf__weights': ['uniform', 'distance']}]\n",
    "\n",
    "    model = GridSearchCV(estimator=pipe_svc,param_grid=param_grid, cv = 5, scoring=make_scorer(roc_auc_score), return_train_score=True, n_jobs = -1)\n",
    "    model.fit(x_train, y_train)\n",
    "    return model\n",
    "\n",
    "def train_linear_svm(x_train, y_train):\n",
    "    # Define simple pipeline\n",
    "    pipe_svc = Pipeline((\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"clf\", SVC())\n",
    "    ))\n",
    "    # Establish params\n",
    "    param_grid = [#{'clf__kernel': ['linear'], 'clf__C': [0.1,1,10,100]},\n",
    "                 {'clf__kernel': ['rbf'], 'clf__gamma': [1e-1,1e-2, 1e-3, 1e-4], 'clf__C': [0.01,0.1,1,10, 100,1000]}]\n",
    "\n",
    "    model = GridSearchCV(estimator=pipe_svc,param_grid=param_grid, cv = 5, scoring=make_scorer(roc_auc_score), return_train_score=True, n_jobs = -1)\n",
    "    model.fit(x_train, y_train)\n",
    "    return model\n",
    "\n",
    "def read_last_results(file, ncolumns, npatients):\n",
    "    if os.path.isfile(file):\n",
    "        past_df = pd.read_csv(file, delimiter=',')\n",
    "    else:\n",
    "        zero_data = np.zeros([npatients, ncolumns])\n",
    "        past_df = pd.DataFrame(zero_data, columns = column_names)\n",
    "    return past_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(ratio, nchannels, patients):\n",
    "    \n",
    "    data_svm = np.zeros(8)\n",
    "    data_rnf = np.zeros(8)\n",
    "    data_knn = np.zeros(8)\n",
    "    for i, patient in enumerate(patients):\n",
    "        \n",
    "        # Calculate most significant channels for patient\n",
    "        channelsdf = pd.read_csv('..\\DataSetCreation\\DataSetsDetection\\\\' + patient + '_channel_order.csv', delimiter=',')\n",
    "        best_channels = get_best_channels(channelsdf, nchannels)\n",
    "\n",
    "        # Read the patient dataframe\n",
    "        df = pd.read_hdf('..\\DataSetCreation\\DataSetsDetection\\\\' + patient + 'features.h5', key = 'fullpatient')\n",
    "\n",
    "        # Extract only the best channels\n",
    "        df = eval(get_expression(best_channels))\n",
    "        df = df.drop(['channel'], axis=1)\n",
    "\n",
    "        # Split the dataframe into train and test\n",
    "        x_train, y_train, x_test, y_test = split_proportional(df, ratio, 'seizure')\n",
    "\n",
    "        # Train models\n",
    "        svc_clf = train_linear_svm(x_train, y_train)\n",
    "        rnf_clf = train_random_forest(x_train, y_train)\n",
    "        knn_clf = train_knn(x_train, y_train)\n",
    "\n",
    "        # Results for SVM model\n",
    "        y_train_pred = svc_clf.predict(x_train)\n",
    "        y_true, y_pred = y_test, svc_clf.predict(x_test)\n",
    "    \n",
    "        # Add result to the csv file\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        sensitivity = cm[1][1]/(cm[1][1] + cm[1][0])\n",
    "        specificity = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "        precision = cm[1][1]/(cm[1][1] + cm[0][1])\n",
    "        roc_score = roc_auc_score(y_true, y_pred)\n",
    "        accuracy = (cm[0][0]+cm[1][1])/(sum(cm))\n",
    "\n",
    "        data_svm = np.vstack((data_svm, np.array([patient, 'svm_rbf', str(svc_clf.best_params_), sensitivity, specificity, roc_score, precision, accuracy])))\n",
    "\n",
    "\n",
    "        # Results for RandomForest model\n",
    "        y_train_pred = rnf_clf.predict(x_train)\n",
    "        y_true, y_pred = y_test, rnf_clf.predict(x_test)\n",
    "\n",
    "        # Add result to the csv file\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        sensitivity = cm[1][1]/(cm[1][1] + cm[1][0])\n",
    "        specificity = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "        precision = cm[1][1]/(cm[1][1] + cm[0][1])\n",
    "        roc_score = roc_auc_score(y_true, y_pred)\n",
    "        accuracy = (cm[0][0]+cm[1][1])/(sum(cm))\n",
    "\n",
    "        # Replace if better results\n",
    "        data_rnf = np.vstack((data_rnf, np.array([patient, 'rnf', str(rnf_clf.best_params_), sensitivity, specificity, roc_score, precision, accuracy])))\n",
    "\n",
    "        # Results for KNN model\n",
    "        y_train_pred = knn_clf.predict(x_train)\n",
    "        y_true, y_pred = y_test, knn_clf.predict(x_test)\n",
    "\n",
    "        # Add result to the csv file\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        sensitivity = cm[1][1]/(cm[1][1] + cm[1][0])\n",
    "        specificity = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "        precision = cm[1][1]/(cm[1][1] + cm[0][1])\n",
    "        roc_score = roc_auc_score(y_true, y_pred)\n",
    "        accuracy = (cm[0][0]+cm[1][1])/(sum(cm))\n",
    "\n",
    "        # Replace if better results\n",
    "        data_knn = np.vstack((data_knn, np.array([patient, 'knn', str(knn_clf.best_params_), sensitivity, specificity, roc_score, precision, accuracy])))\n",
    "            \n",
    "    return data_svm, data_rnf, data_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished with ratio 0.2\n",
      "Finished with ratio 0.3\n",
      "Finished with ratio 0.4\n",
      "Finished with ratio 0.5\n",
      "Finished with ratio 0.6\n",
      "Finished with ratio 0.7\n",
      "Finished with ratio 0.8\n"
     ]
    }
   ],
   "source": [
    "patients = ['chb01', 'chb02', 'chb03', 'chb04', 'chb05', 'chb06', 'chb07', 'chb08', 'chb09','chb10', 'chb11',\n",
    "            'chb13', 'chb14', 'chb15', 'chb16', 'chb17', 'chb18', 'chb19', 'chb20', 'chb21', 'chb22', 'chb23']\n",
    "\n",
    "ratios = list(range(2, 9))\n",
    "ratios = [ratio/10 for ratio in ratios]\n",
    "\n",
    "column_names = ['patient', 'model', 'hyperparameters', 'sensitivity', 'specificity', 'roc_auc', 'precision', 'accuracy']\n",
    "nchannels = 1\n",
    "\n",
    "for ratio in ratios:\n",
    "    data_svm, data_rnf, data_knn = train_models(ratio, nchannels, patients)\n",
    "\n",
    "    # Save df to csv file\n",
    "    data_svm = data_svm[1:, :]\n",
    "    dataframe_svm = pd.DataFrame(data_svm, columns = column_names)\n",
    "    dataframe_svm.set_index('patient')\n",
    "    dataframe_svm.to_csv(basedir + '\\\\diferent_ratios_scores\\\\svm_rbf_' + str(ratio) + 'ratio.csv', index=False)\n",
    "\n",
    "    # Save df to csv file\n",
    "    data_rnf = data_rnf[1:, :]\n",
    "    dataframe_rnf = pd.DataFrame(data_rnf, columns = column_names)\n",
    "    dataframe_rnf.set_index('patient')\n",
    "    dataframe_rnf.to_csv(basedir + '\\\\diferent_ratios_scores\\\\rnf_' + str(ratio) + 'ratio.csv', index=False)\n",
    "\n",
    "    # Save df to csv file\n",
    "    data_knn = data_knn[1:, :]\n",
    "    dataframe_knn = pd.DataFrame(data_knn, columns = column_names)\n",
    "    dataframe_knn.set_index('patient')\n",
    "    dataframe_knn.to_csv(basedir + '\\\\diferent_ratios_scores\\\\knn_' + str(ratio) + 'ratio.csv', index=False)\n",
    "    \n",
    "    print('Finished with ratio {}'.format(ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
