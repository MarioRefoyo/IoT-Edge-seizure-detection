{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "import glob, os\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, make_scorer, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = os.getcwd()\n",
    "os.chdir(basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_channels(channelsdf, nchannels=2):\n",
    "    \n",
    "    list_of_rows = [list(row) for row in channelsdf.values]\n",
    "    \n",
    "    channel_score_dict = {}\n",
    "    for i, elem in enumerate(list_of_rows[0]):\n",
    "        channel_score_dict[elem] = i\n",
    "\n",
    "    for row, rowlist in enumerate(list_of_rows[1:]):\n",
    "        for i, elem in enumerate(rowlist):\n",
    "            channel_score_dict[elem] = channel_score_dict[elem] + i\n",
    "\n",
    "    sorted_channels = sorted(channel_score_dict, key=channel_score_dict.get)\n",
    "    best_channels = sorted_channels[:nchannels]\n",
    "    \n",
    "    return best_channels\n",
    "\n",
    "def get_expression(channels):\n",
    "    expression = 'patient_df['\n",
    "    for channel in best_channels:\n",
    "        expression +='(patient_df[\\'channel\\'] == \\'' + channel + '\\')|'\n",
    "    return expression[:-1] + ']'\n",
    "\n",
    "def split_train_test(data, test_ratio):\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_set = data.iloc[:test_set_size]\n",
    "    train_set = data.iloc[test_set_size:]\n",
    "    return train_set, test_set\n",
    "\n",
    "def split_proportional(dataframe, test_ratio, target):\n",
    "    dataframe = dataframe.sample(frac=1)\n",
    "    df_seizures = dataframe[dataframe[target] == True]\n",
    "    df_normal = dataframe[dataframe[target] == False]\n",
    "    \n",
    "    train_seizures, test_seizures = split_train_test(df_seizures, test_ratio)\n",
    "    train_normal, test_normal = split_train_test(df_normal, test_ratio)\n",
    "    \n",
    "    df_train = pd.concat([train_normal, train_seizures], axis=0).reset_index()\n",
    "    x_train, y_train = df_train[df_train.columns.difference([target])], df_train[target]\n",
    "    df_test = pd.concat([test_normal, test_seizures], axis=0).reset_index()\n",
    "    x_test, y_test = df_test[df_test.columns.difference([target])], df_test[target]\n",
    "    \n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def train_random_forest(x_train, y_train):\n",
    "    # Define simple pipeline\n",
    "    pipe_rnf = Pipeline((\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"clf\", RandomForestClassifier())\n",
    "    ))\n",
    "    # Establish params\n",
    "    param_grid = [\n",
    "                 {'clf__n_estimators': [50, 100, 200, 300, 400, 500], 'clf__max_leaf_nodes': [4,8,16,32,64]}]\n",
    "\n",
    "    model = GridSearchCV(estimator=pipe_rnf,param_grid=param_grid, cv = 5, scoring=make_scorer(roc_auc_score), return_train_score=True, n_jobs = -1)\n",
    "    model.fit(x_train, y_train)\n",
    "    return model\n",
    "\n",
    "def train_knn(x_train, y_train):\n",
    "    # Define simple pipeline\n",
    "    pipe_svc = Pipeline((\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"clf\", KNeighborsClassifier())\n",
    "    ))\n",
    "\n",
    "    param_grid = [{'clf__n_neighbors': list(range(11)), 'clf__p': [1,2], 'clf__weights': ['uniform', 'distance']}]\n",
    "\n",
    "    model = GridSearchCV(estimator=pipe_svc,param_grid=param_grid, cv = 5, scoring=make_scorer(roc_auc_score), return_train_score=True, n_jobs = -1)\n",
    "    model.fit(x_train, y_train)\n",
    "    return model\n",
    "\n",
    "def train_linear_svm(x_train, y_train):\n",
    "    # Define simple pipeline\n",
    "    pipe_svc = Pipeline((\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"clf\", SVC())\n",
    "    ))\n",
    "    # Establish params\n",
    "    param_grid = [#{'clf__kernel': ['linear'], 'clf__C': [0.1,1,10,100]},\n",
    "                 {'clf__kernel': ['rbf'], 'clf__gamma': [1e-1,1e-2, 1e-3, 1e-4], 'clf__C': [0.01,0.1,1,10, 100,1000]}]\n",
    "\n",
    "    model = GridSearchCV(estimator=pipe_svc,param_grid=param_grid, cv = 5, scoring=make_scorer(roc_auc_score), return_train_score=True, n_jobs = -1)\n",
    "    model.fit(x_train, y_train)\n",
    "    return model\n",
    "\n",
    "def read_last_results(file, ncolumns, npatients):\n",
    "    if os.path.isfile(file):\n",
    "        past_df = pd.read_csv(file, delimiter=',')\n",
    "    else:\n",
    "        zero_data = np.zeros([npatients, ncolumns])\n",
    "        past_df = pd.DataFrame(zero_data, columns = column_names)\n",
    "    return past_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = ['chb01', 'chb02', 'chb03', 'chb05', 'chb07', 'chb08', 'chb09','chb10', 'chb11',\n",
    "            'chb13', 'chb14', 'chb15', 'chb16', 'chb17', 'chb18', 'chb19', 'chb20', 'chb21', 'chb22', 'chb23']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nchannels = 1\n",
    "\n",
    "# Open file to store the results in a txt format, more detailed than the csv\n",
    "f = open(basedir + '\\\\results_welch\\\\results' + str(nchannels) + 'channels.txt',\"w+\")\n",
    "\n",
    "dataframe = pd.DataFrame()\n",
    "for i, patient in enumerate(patients):\n",
    "    # Calculate most significant channels for patient\n",
    "    channelsdf = pd.read_csv('..\\DataSetCreation\\DataSetsWelch\\\\' + patient + '_channel_order.csv', delimiter=',')\n",
    "    best_channels = get_best_channels(channelsdf, nchannels)\n",
    "    \n",
    "    # Read the patient dataframe\n",
    "    patient_df = pd.read_hdf('..\\DataSetCreation\\DataSetsWelch\\\\' + patient + 'features.h5', key = 'fullpatient')\n",
    "    \n",
    "    # Extract only the best channels\n",
    "    patient_df = eval(get_expression(best_channels))\n",
    "    patient_df = patient_df.drop(['channel'], axis=1)\n",
    "    dataframe = dataframe.append(patient_df, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>std</th>\n",
       "      <th>zero_crossings</th>\n",
       "      <th>peak2peak</th>\n",
       "      <th>total_energy</th>\n",
       "      <th>delta</th>\n",
       "      <th>theta</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>gamma</th>\n",
       "      <th>seizure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.163932</td>\n",
       "      <td>3154.293104</td>\n",
       "      <td>0.132924</td>\n",
       "      <td>-0.368701</td>\n",
       "      <td>56.163094</td>\n",
       "      <td>62.0</td>\n",
       "      <td>294.850406</td>\n",
       "      <td>5181.014869</td>\n",
       "      <td>2212.371990</td>\n",
       "      <td>2262.965153</td>\n",
       "      <td>884.035069</td>\n",
       "      <td>164.850940</td>\n",
       "      <td>97.218538</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.363003</td>\n",
       "      <td>12616.597818</td>\n",
       "      <td>0.257843</td>\n",
       "      <td>1.596332</td>\n",
       "      <td>112.323630</td>\n",
       "      <td>50.0</td>\n",
       "      <td>734.158928</td>\n",
       "      <td>25164.604639</td>\n",
       "      <td>21904.924142</td>\n",
       "      <td>3090.354751</td>\n",
       "      <td>582.918383</td>\n",
       "      <td>202.580573</td>\n",
       "      <td>156.068159</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.393524</td>\n",
       "      <td>33270.889695</td>\n",
       "      <td>-0.220567</td>\n",
       "      <td>-0.275883</td>\n",
       "      <td>182.403097</td>\n",
       "      <td>26.0</td>\n",
       "      <td>936.005650</td>\n",
       "      <td>71700.884842</td>\n",
       "      <td>64830.573651</td>\n",
       "      <td>6569.391804</td>\n",
       "      <td>561.658893</td>\n",
       "      <td>482.070473</td>\n",
       "      <td>420.365466</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.462458</td>\n",
       "      <td>35728.106631</td>\n",
       "      <td>-0.498677</td>\n",
       "      <td>-0.470689</td>\n",
       "      <td>189.018800</td>\n",
       "      <td>23.0</td>\n",
       "      <td>936.005650</td>\n",
       "      <td>72582.043554</td>\n",
       "      <td>67424.964543</td>\n",
       "      <td>4927.892459</td>\n",
       "      <td>624.006343</td>\n",
       "      <td>496.495812</td>\n",
       "      <td>480.370363</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.919438</td>\n",
       "      <td>29569.069241</td>\n",
       "      <td>-0.502099</td>\n",
       "      <td>-0.464093</td>\n",
       "      <td>171.956591</td>\n",
       "      <td>30.0</td>\n",
       "      <td>823.965651</td>\n",
       "      <td>64397.121875</td>\n",
       "      <td>61265.210019</td>\n",
       "      <td>2762.673411</td>\n",
       "      <td>605.275561</td>\n",
       "      <td>364.707896</td>\n",
       "      <td>249.885274</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174082</th>\n",
       "      <td>-0.271013</td>\n",
       "      <td>3564.393389</td>\n",
       "      <td>1.268979</td>\n",
       "      <td>5.233157</td>\n",
       "      <td>59.702541</td>\n",
       "      <td>32.0</td>\n",
       "      <td>446.509767</td>\n",
       "      <td>8725.740848</td>\n",
       "      <td>8371.484274</td>\n",
       "      <td>349.646641</td>\n",
       "      <td>75.770720</td>\n",
       "      <td>37.133015</td>\n",
       "      <td>11.331364</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174083</th>\n",
       "      <td>1.075107</td>\n",
       "      <td>3628.772178</td>\n",
       "      <td>0.503217</td>\n",
       "      <td>3.639426</td>\n",
       "      <td>60.239291</td>\n",
       "      <td>36.0</td>\n",
       "      <td>428.498851</td>\n",
       "      <td>6177.260433</td>\n",
       "      <td>5869.016319</td>\n",
       "      <td>320.436035</td>\n",
       "      <td>58.575865</td>\n",
       "      <td>42.385116</td>\n",
       "      <td>11.007761</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174084</th>\n",
       "      <td>1.128110</td>\n",
       "      <td>5218.158539</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>1.296146</td>\n",
       "      <td>72.236823</td>\n",
       "      <td>116.0</td>\n",
       "      <td>453.529925</td>\n",
       "      <td>11701.546846</td>\n",
       "      <td>8917.557022</td>\n",
       "      <td>501.591204</td>\n",
       "      <td>119.130557</td>\n",
       "      <td>1226.429930</td>\n",
       "      <td>1220.274505</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174085</th>\n",
       "      <td>-4.879393</td>\n",
       "      <td>3965.977528</td>\n",
       "      <td>0.591510</td>\n",
       "      <td>1.221693</td>\n",
       "      <td>62.976008</td>\n",
       "      <td>136.0</td>\n",
       "      <td>434.273711</td>\n",
       "      <td>9269.266473</td>\n",
       "      <td>3681.251974</td>\n",
       "      <td>340.533554</td>\n",
       "      <td>236.832740</td>\n",
       "      <td>2046.884185</td>\n",
       "      <td>3170.397058</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174086</th>\n",
       "      <td>-0.301323</td>\n",
       "      <td>3931.269315</td>\n",
       "      <td>0.319503</td>\n",
       "      <td>1.147675</td>\n",
       "      <td>62.699835</td>\n",
       "      <td>125.0</td>\n",
       "      <td>424.548935</td>\n",
       "      <td>6818.167684</td>\n",
       "      <td>2625.854200</td>\n",
       "      <td>401.592893</td>\n",
       "      <td>253.546259</td>\n",
       "      <td>1881.181100</td>\n",
       "      <td>1810.336607</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174087 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean      variance  skewness  kurtosis         std  \\\n",
       "0       0.163932   3154.293104  0.132924 -0.368701   56.163094   \n",
       "1      -3.363003  12616.597818  0.257843  1.596332  112.323630   \n",
       "2      -2.393524  33270.889695 -0.220567 -0.275883  182.403097   \n",
       "3       4.462458  35728.106631 -0.498677 -0.470689  189.018800   \n",
       "4       5.919438  29569.069241 -0.502099 -0.464093  171.956591   \n",
       "...          ...           ...       ...       ...         ...   \n",
       "174082 -0.271013   3564.393389  1.268979  5.233157   59.702541   \n",
       "174083  1.075107   3628.772178  0.503217  3.639426   60.239291   \n",
       "174084  1.128110   5218.158539  0.348837  1.296146   72.236823   \n",
       "174085 -4.879393   3965.977528  0.591510  1.221693   62.976008   \n",
       "174086 -0.301323   3931.269315  0.319503  1.147675   62.699835   \n",
       "\n",
       "        zero_crossings   peak2peak  total_energy         delta        theta  \\\n",
       "0                 62.0  294.850406   5181.014869   2212.371990  2262.965153   \n",
       "1                 50.0  734.158928  25164.604639  21904.924142  3090.354751   \n",
       "2                 26.0  936.005650  71700.884842  64830.573651  6569.391804   \n",
       "3                 23.0  936.005650  72582.043554  67424.964543  4927.892459   \n",
       "4                 30.0  823.965651  64397.121875  61265.210019  2762.673411   \n",
       "...                ...         ...           ...           ...          ...   \n",
       "174082            32.0  446.509767   8725.740848   8371.484274   349.646641   \n",
       "174083            36.0  428.498851   6177.260433   5869.016319   320.436035   \n",
       "174084           116.0  453.529925  11701.546846   8917.557022   501.591204   \n",
       "174085           136.0  434.273711   9269.266473   3681.251974   340.533554   \n",
       "174086           125.0  424.548935   6818.167684   2625.854200   401.592893   \n",
       "\n",
       "             alpha         beta        gamma  seizure  \n",
       "0       884.035069   164.850940    97.218538     True  \n",
       "1       582.918383   202.580573   156.068159     True  \n",
       "2       561.658893   482.070473   420.365466     True  \n",
       "3       624.006343   496.495812   480.370363     True  \n",
       "4       605.275561   364.707896   249.885274     True  \n",
       "...            ...          ...          ...      ...  \n",
       "174082   75.770720    37.133015    11.331364    False  \n",
       "174083   58.575865    42.385116    11.007761    False  \n",
       "174084  119.130557  1226.429930  1220.274505    False  \n",
       "174085  236.832740  2046.884185  3170.397058    False  \n",
       "174086  253.546259  1881.181100  1810.336607    False  \n",
       "\n",
       "[174087 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM finished\n",
      "RNF finished\n",
      "KNN finished\n"
     ]
    }
   ],
   "source": [
    "# Split the dataframe into train and test\n",
    "x_train, y_train, x_test, y_test = split_proportional(dataframe, 0.2, 'seizure')\n",
    "    \n",
    "# Train models\n",
    "svc_clf = train_linear_svm(x_train, y_train)\n",
    "print('SVM finished')\n",
    "rnf_clf = train_random_forest(x_train, y_train)\n",
    "print('RNF finished')\n",
    "knn_clf = train_knn(x_train, y_train)\n",
    "print('KNN finished')\n",
    "    \n",
    "# Results for SVM model\n",
    "y_train_pred = svc_clf.predict(x_train)\n",
    "y_true, y_pred = y_test, svc_clf.predict(x_test)\n",
    "    \n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sensitivity = cm[1][1]/(cm[1][1] + cm[1][0])\n",
    "specificity = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "precision = cm[1][1]/(cm[1][1] + cm[0][1])\n",
    "roc_score = roc_auc_score(y_true, y_pred)\n",
    "accuracy = (cm[0][0]+cm[1][1])/(sum(cm)) \n",
    "data_svm = np.array(['svm_rbf', str(svc_clf.best_params_), sensitivity, specificity, roc_score, precision, accuracy])\n",
    "\n",
    "        \n",
    "# Results for RandomForest model\n",
    "y_train_pred = rnf_clf.predict(x_train)\n",
    "y_true, y_pred = y_test, rnf_clf.predict(x_test) \n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sensitivity = cm[1][1]/(cm[1][1] + cm[1][0])\n",
    "specificity = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "precision = cm[1][1]/(cm[1][1] + cm[0][1])\n",
    "roc_score = roc_auc_score(y_true, y_pred)\n",
    "accuracy = (cm[0][0]+cm[1][1])/(sum(cm))\n",
    "data_rnf = np.array(['rnf', str(rnf_clf.best_params_), sensitivity, specificity, roc_score, precision, accuracy])\n",
    "\n",
    "        \n",
    "# Results for KNN model\n",
    "y_train_pred = knn_clf.predict(x_train)\n",
    "y_true, y_pred = y_test, knn_clf.predict(x_test)\n",
    "    \n",
    "# Add result to the csv file\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sensitivity = cm[1][1]/(cm[1][1] + cm[1][0])\n",
    "specificity = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "precision = cm[1][1]/(cm[1][1] + cm[0][1])\n",
    "roc_score = roc_auc_score(y_true, y_pred)\n",
    "accuracy = (cm[0][0]+cm[1][1])/(sum(cm))\n",
    "    \n",
    "data_knn = np.array(['knn', str(knn_clf.best_params_), sensitivity, specificity, roc_score, precision, accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['model', 'hyperparameters', 'sensitivity', 'specificity', 'roc_auc', 'precision', 'accuracy']\n",
    "\n",
    "results = np.array([data_svm, data_rnf, data_knn])\n",
    "results_df = pd.DataFrame(results, columns = column_names)\n",
    "\n",
    "# Save df to csv file\n",
    "results_df.set_index('model')\n",
    "results_df.to_csv(basedir + '\\\\results_welch\\\\general_' + str(nchannels) + 'channels.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3, 4, 5])\n",
    "b = np.array([1, 2, 3, 4, 5])\n",
    "c = np.array([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix = np.array([a, b, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5],\n",
       "       [1, 2, 3, 4, 5]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(mix, columns = ['uno', 'dos', 'tres', 'cuatro', 'cinco'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uno</th>\n",
       "      <th>dos</th>\n",
       "      <th>tres</th>\n",
       "      <th>cuatro</th>\n",
       "      <th>cinco</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uno  dos  tres  cuatro  cinco\n",
       "0    1    2     3       4      5\n",
       "1    1    2     3       4      5\n",
       "2    1    2     3       4      5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
