{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "import glob, os\n",
    "import pickle\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, make_scorer, average_precision_score\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = os.getcwd()\n",
    "os.chdir(basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_channels(channelsdf, nchannels=2):\n",
    "    \n",
    "    list_of_rows = [list(row) for row in channelsdf.values]\n",
    "    \n",
    "    channel_score_dict = {}\n",
    "    for i, elem in enumerate(list_of_rows[0]):\n",
    "        channel_score_dict[elem] = i\n",
    "\n",
    "    for row, rowlist in enumerate(list_of_rows[1:]):\n",
    "        for i, elem in enumerate(rowlist):\n",
    "            channel_score_dict[elem] = channel_score_dict[elem] + i\n",
    "\n",
    "    sorted_channels = sorted(channel_score_dict, key=channel_score_dict.get)\n",
    "    best_channels = sorted_channels[:nchannels]\n",
    "    \n",
    "    return best_channels\n",
    "\n",
    "def get_expression(channels):\n",
    "    expression = 'df['\n",
    "    for channel in best_channels:\n",
    "        expression +='(df[\\'channel\\'] == \\'' + channel + '\\')|'\n",
    "    return expression[:-1] + ']'\n",
    "\n",
    "def split_train_test(data, test_ratio):\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_set = data.iloc[:test_set_size]\n",
    "    train_set = data.iloc[test_set_size:]\n",
    "    return train_set, test_set\n",
    "\n",
    "def split_proportional(dataframe, test_ratio, target):\n",
    "    dataframe = dataframe.sample(frac=1)\n",
    "    df_seizures = dataframe[dataframe[target] == True]\n",
    "    df_normal = dataframe[dataframe[target] == False]\n",
    "    \n",
    "    train_seizures, test_seizures = split_train_test(df_seizures, test_ratio)\n",
    "    train_normal, test_normal = split_train_test(df_normal, test_ratio)\n",
    "    \n",
    "    df_train = pd.concat([train_normal, train_seizures], axis=0)\n",
    "    df_train = df_train.sample(frac=1)\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    x_train, y_train = df_train[df_train.columns.difference([target])], df_train[target]\n",
    "    \n",
    "    df_test = pd.concat([test_normal, test_seizures], axis=0)\n",
    "    df_test = df_test.sample(frac=1)\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "    x_test, y_test = df_test[df_test.columns.difference([target])], df_test[target]\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def train_random_forest(x_train, y_train):\n",
    "    # Define simple pipeline\n",
    "    pipe_rnf = Pipeline((\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"clf\", RandomForestClassifier())\n",
    "    ))\n",
    "    # Establish params\n",
    "    param_grid = [\n",
    "                 {'clf__n_estimators': [50, 100, 200, 300, 400, 500], 'clf__max_leaf_nodes': [4,8,16,32,64]}]\n",
    "\n",
    "    model = GridSearchCV(estimator=pipe_rnf,param_grid=param_grid, cv = 5, scoring=make_scorer(roc_auc_score), return_train_score=True, n_jobs = -1)\n",
    "    model.fit(x_train, y_train)\n",
    "    return model\n",
    "\n",
    "def train_knn(x_train, y_train):\n",
    "    # Define simple pipeline\n",
    "    pipe_svc = Pipeline((\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"clf\", KNeighborsClassifier())\n",
    "    ))\n",
    "\n",
    "    param_grid = [{'clf__n_neighbors': list(range(11)), 'clf__p': [1,2], 'clf__weights': ['uniform', 'distance']}]\n",
    "\n",
    "    model = GridSearchCV(estimator=pipe_svc,param_grid=param_grid, cv = 5, scoring=make_scorer(roc_auc_score), return_train_score=True, n_jobs = -1)\n",
    "    model.fit(x_train, y_train)\n",
    "    return model\n",
    "\n",
    "def train_linear_svm(x_train, y_train):\n",
    "    # Define simple pipeline\n",
    "    pipe_svc = Pipeline((\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"clf\", SVC())\n",
    "    ))\n",
    "    # Establish params\n",
    "    param_grid = [#{'clf__kernel': ['linear'], 'clf__C': [0.1,1,10,100]},\n",
    "                 {'clf__kernel': ['rbf'], 'clf__gamma': [1e-1,1e-2, 1e-3, 1e-4], 'clf__C': [0.01,0.1,1,10, 100,1000], 'clf__probability': [True]}]\n",
    "\n",
    "    model = GridSearchCV(estimator=pipe_svc,param_grid=param_grid, cv = 5, scoring=make_scorer(roc_auc_score), return_train_score=True, n_jobs = -1)\n",
    "    model.fit(x_train, y_train)\n",
    "    return model\n",
    "\n",
    "def read_last_results(file, ncolumns, npatients):\n",
    "    if os.path.isfile(file):\n",
    "        past_df = pd.read_csv(file, delimiter=',')\n",
    "    else:\n",
    "        zero_data = np.zeros([npatients, ncolumns])\n",
    "        past_df = pd.DataFrame(zero_data, columns = column_names)\n",
    "    return past_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = ['chb01', 'chb02', 'chb03', 'chb04', 'chb05','chb06', 'chb07', 'chb08', 'chb09','chb10', 'chb11',\n",
    "            'chb13', 'chb14', 'chb15', 'chb16', 'chb17', 'chb18', 'chb19', 'chb20', 'chb21', 'chb22', 'chb23']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- Finished report for patient chb01 -----------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    908\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    561\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-fef960d1949f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;31m# Train models\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0msvc_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_linear_svm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mrnf_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_random_forest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0mknn_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_knn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-ad3aacacf3ed>\u001b[0m in \u001b[0;36mtrain_random_forest\u001b[1;34m(x_train, y_train)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpipe_rnf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    708\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1151\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    687\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 689\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    929\u001b[0m                     \u001b[1;31m# scheduling.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m                     \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTransportableException\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mabort_everything\u001b[1;34m(self, ensure_ready)\u001b[0m\n\u001b[0;32m    577\u001b[0m         \"\"\"Shutdown the workers and restart a new one with the same parameters\n\u001b[0;32m    578\u001b[0m         \"\"\"\n\u001b[1;32m--> 579\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkill_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m         \u001b[0mdelete_folder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_temp_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\u001b[0m in \u001b[0;36mshutdown\u001b[1;34m(self, wait, kill_workers)\u001b[0m\n\u001b[0;32m   1099\u001b[0m                     \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1101\u001b[1;33m                 \u001b[0mqmt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m         \u001b[0mcq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_queue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m             \u001b[1;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m   1058\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# already determined that the C code is done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1060\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1061\u001b[0m             \u001b[0mlock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nchannels = 1\n",
    "column_names = ['patient', 'model', 'hyperparameters', 'sensitivity', 'specificity', 'roc_auc', 'precision', 'accuracy']\n",
    "\n",
    "past_df_svm = read_last_results(basedir + '\\\\results_detection\\\\svm_rbf_' + str(nchannels) + 'channels.csv', len(column_names), len(patients))\n",
    "past_df_rnf = read_last_results(basedir + '\\\\results_detection\\\\rnf_' + str(nchannels) + 'channels.csv', len(column_names), len(patients))\n",
    "past_df_knn = read_last_results(basedir + '\\\\results_detection\\\\knn_' + str(nchannels) + 'channels.csv', len(column_names), len(patients))\n",
    "\n",
    "# Open file to store the results in a txt format, more detailed than the csv\n",
    "f = open(basedir + '\\\\results_detection\\\\results' + str(nchannels) + 'channels.txt',\"w+\")\n",
    "\n",
    "data_svm = np.zeros(8)\n",
    "data_rnf = np.zeros(8)\n",
    "data_knn = np.zeros(8)\n",
    "for i, patient in enumerate(patients):\n",
    "    # Calculate most significant channels for patient\n",
    "    channelsdf = pd.read_csv('..\\DataSetCreation\\DataSetsDetection\\\\' + patient + '_channel_order.csv', delimiter=',')\n",
    "    best_channels = get_best_channels(channelsdf, nchannels)\n",
    "    \n",
    "    # Read the patient dataframe\n",
    "    df = pd.read_hdf('..\\DataSetCreation\\DataSetsDetection\\\\' + patient + 'features.h5', key = 'fullpatient')\n",
    "    \n",
    "    # Extract only the best channels\n",
    "    df = eval(get_expression(best_channels))\n",
    "    df = df.drop(['channel'], axis=1)\n",
    "    \n",
    "    # Split the dataframe into train and test\n",
    "    x_train, y_train, x_test, y_test = split_proportional(df, 0.2, 'seizure')\n",
    "    \n",
    "    # Train models\n",
    "    svc_clf = train_linear_svm(x_train, y_train)\n",
    "    rnf_clf = train_random_forest(x_train, y_train)\n",
    "    knn_clf = train_knn(x_train, y_train)\n",
    "    \n",
    "    # Results for SVM model\n",
    "    y_train_pred = svc_clf.predict(x_train)\n",
    "    y_true, y_pred = y_test, svc_clf.predict(x_test)\n",
    "    f.write('-------------------------- Patient ' + patient + ' ------------------------------------\\n')\n",
    "    f.write(str(svc_clf.best_params_) + '\\n')\n",
    "    \n",
    "    # Predict and see final model\n",
    "    f.write(classification_report(y_train, y_train_pred) + '\\n')\n",
    "    f.write(classification_report(y_true, y_pred) + '\\n')\n",
    "    \n",
    "    print('---------------------- Finished report for patient ' + patient + ' -----------------------')\n",
    "    f.write('---------------------- Finished report for patient ' + patient + ' -----------------------\\n\\n\\n')\n",
    "    \n",
    "    # Add result to the csv file\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sensitivity = cm[1][1]/(cm[1][1] + cm[1][0])\n",
    "    specificity = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "    precision = cm[1][1]/(cm[1][1] + cm[0][1])\n",
    "    roc_score = roc_auc_score(y_true, y_pred)\n",
    "    accuracy = (cm[0][0]+cm[1][1])/(sum(cm))\n",
    "    \n",
    "    # Replace if better results\n",
    "    if (sensitivity + specificity )/2 > (past_df_svm.iloc[i]['sensitivity'] + past_df_svm.iloc[i]['specificity'])/2:\n",
    "        data_svm = np.vstack((data_svm, np.array([patient, 'svm_rbf', str(svc_clf.best_params_), sensitivity, specificity, roc_score, precision, accuracy])))\n",
    "        pickle.dump(svc_clf, open(basedir + '\\\\results_detection\\\\' + 'svm_{}.sav'.format(patient), 'wb'))\n",
    "        dump(svc_clf, 'svm_{}.joblib'.format(patient)) \n",
    "    else: \n",
    "        data_svm = np.vstack((data_svm, past_df_svm.iloc[i].values))\n",
    "        \n",
    "    # Results for RandomForest model\n",
    "    y_train_pred = rnf_clf.predict(x_train)\n",
    "    y_true, y_pred = y_test, rnf_clf.predict(x_test)\n",
    "    \n",
    "    # Add result to the csv file\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sensitivity = cm[1][1]/(cm[1][1] + cm[1][0])\n",
    "    specificity = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "    precision = cm[1][1]/(cm[1][1] + cm[0][1])\n",
    "    roc_score = roc_auc_score(y_true, y_pred)\n",
    "    accuracy = (cm[0][0]+cm[1][1])/(sum(cm))\n",
    "    \n",
    "    # Replace if better results\n",
    "    if (sensitivity + specificity )/2 > (past_df_rnf.iloc[i]['sensitivity'] + past_df_rnf.iloc[i]['specificity'])/2:\n",
    "        data_rnf = np.vstack((data_rnf, np.array([patient, 'rnf', str(rnf_clf.best_params_), sensitivity, specificity, roc_score, precision, accuracy])))\n",
    "        #pickle.dump(rnf_clf, open(basedir + '\\\\results_detection\\\\' + 'rnf_{}.sav'.format(patient), 'wb'))\n",
    "        dump(rnf_clf, 'rnf_{}.joblib'.format(patient)) \n",
    "    else: \n",
    "        data_rnf = np.vstack((data_rnf, past_df_rnf.iloc[i].values))\n",
    "        \n",
    "    # Results for KNN model\n",
    "    y_train_pred = knn_clf.predict(x_train)\n",
    "    y_true, y_pred = y_test, knn_clf.predict(x_test)\n",
    "    \n",
    "    # Add result to the csv file\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sensitivity = cm[1][1]/(cm[1][1] + cm[1][0])\n",
    "    specificity = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "    precision = cm[1][1]/(cm[1][1] + cm[0][1])\n",
    "    roc_score = roc_auc_score(y_true, y_pred)\n",
    "    accuracy = (cm[0][0]+cm[1][1])/(sum(cm))\n",
    "    \n",
    "    # Replace if better results\n",
    "    if (sensitivity + specificity )/2 > (past_df_knn.iloc[i]['sensitivity'] + past_df_knn.iloc[i]['specificity'])/2:\n",
    "        data_knn = np.vstack((data_knn, np.array([patient, 'knn', str(knn_clf.best_params_), sensitivity, specificity, roc_score, precision, accuracy])))\n",
    "        pickle.dump(knn_clf, open(basedir + '\\\\results_detection\\\\' + 'knn_{}.sav'.format(patient), 'wb'))\n",
    "    else: \n",
    "        data_knn = np.vstack((data_knn, past_df_knn.iloc[i].values))\n",
    "    \n",
    "    \n",
    "        \n",
    "# Close  text file\n",
    "f.close() \n",
    "\n",
    "# Save df to csv file\n",
    "data_svm = data_svm[1:, :]\n",
    "dataframe_svm = pd.DataFrame(data_svm, columns = column_names)\n",
    "dataframe_svm.set_index('patient')\n",
    "dataframe_svm.to_csv(basedir + '\\\\results_detection\\\\svm_rbf_' + str(nchannels) + 'channels.csv', index=False)\n",
    "\n",
    "# Save df to csv file\n",
    "data_rnf = data_rnf[1:, :]\n",
    "dataframe_rnf = pd.DataFrame(data_rnf, columns = column_names)\n",
    "dataframe_rnf.set_index('patient')\n",
    "dataframe_rnf.to_csv(basedir + '\\\\results_detection\\\\rnf_' + str(nchannels) + 'channels.csv', index=False)\n",
    "\n",
    "# Save df to csv file\n",
    "data_knn = data_knn[1:, :]\n",
    "dataframe_knn = pd.DataFrame(data_knn, columns = column_names)\n",
    "dataframe_knn.set_index('patient')\n",
    "dataframe_knn.to_csv(basedir + '\\\\results_detection\\\\knn_' + str(nchannels) + 'channels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
