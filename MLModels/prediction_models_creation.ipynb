{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "import glob, os\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, make_scorer, average_precision_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = os.getcwd()\n",
    "os.chdir(basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_channels(channelsdf, nchannels=2):\n",
    "    \n",
    "    list_of_rows = [list(row) for row in channelsdf.values]\n",
    "    \n",
    "    channel_score_dict = {}\n",
    "    for i, elem in enumerate(list_of_rows[0]):\n",
    "        channel_score_dict[elem] = i\n",
    "\n",
    "    for row, rowlist in enumerate(list_of_rows[1:]):\n",
    "        for i, elem in enumerate(rowlist):\n",
    "            channel_score_dict[elem] = channel_score_dict[elem] + i\n",
    "\n",
    "    sorted_channels = sorted(channel_score_dict, key=channel_score_dict.get)\n",
    "    best_channels = sorted_channels[:nchannels]\n",
    "    \n",
    "    return best_channels\n",
    "\n",
    "def get_expression(channels):\n",
    "    expression = 'df['\n",
    "    for channel in best_channels:\n",
    "        expression +='(df[\\'channel\\'] == \\'' + channel + '\\')|'\n",
    "    return expression[:-1] + ']'\n",
    "\n",
    "def split_train_test(data, test_ratio):\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_set = data.iloc[:test_set_size]\n",
    "    train_set = data.iloc[test_set_size:]\n",
    "    return train_set, test_set\n",
    "\n",
    "def split_proportional(dataframe, test_ratio, target):\n",
    "    dataframe = dataframe.sample(frac=1)\n",
    "    df_seizures = dataframe[dataframe['seizure'] == 'ictal']\n",
    "    df_normal = dataframe[dataframe['seizure'] == 'inter-ictal']\n",
    "    df_preictal = dataframe[dataframe['seizure'] == 'pre-ictal']\n",
    "    \n",
    "    train_seizures, test_seizures = split_train_test(df_seizures, test_ratio)\n",
    "    train_normal, test_normal = split_train_test(df_normal, test_ratio)\n",
    "    train_preictal, test_preictal = split_train_test(df_preictal, test_ratio)\n",
    "    \n",
    "    df_train = pd.concat([train_normal, train_seizures, train_preictal], axis=0).reset_index()\n",
    "    x_train, y_train = df_train[df_train.columns.difference(['seizure'])], df_train[\"seizure\"]\n",
    "    df_test = pd.concat([test_normal, test_seizures, test_preictal], axis=0).reset_index()\n",
    "    x_test, y_test = df_test[df_test.columns.difference(['seizure'])], df_test[\"seizure\"]\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def train_random_forest(x_train, y_train):\n",
    "    # Define simple pipeline\n",
    "    pipe_rnf = Pipeline((\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"clf\", RandomForestClassifier())\n",
    "    ))\n",
    "    # Establish params\n",
    "    param_grid = [\n",
    "                 {'clf__n_estimators': [50, 100, 200, 300, 400, 500], 'clf__max_leaf_nodes': [4,8,16,32,64]}]\n",
    "\n",
    "    model = GridSearchCV(estimator=pipe_rnf,param_grid=param_grid, cv = 5, return_train_score=True, n_jobs = -1)\n",
    "    model.fit(x_train, y_train)\n",
    "    return model\n",
    "\n",
    "def train_knn(x_train, y_train):\n",
    "    # Define simple pipeline\n",
    "    pipe_svc = Pipeline((\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"clf\", KNeighborsClassifier())\n",
    "    ))\n",
    "\n",
    "    param_grid = [{'clf__n_neighbors': list(range(11)), 'clf__p': [1,2], 'clf__weights': ['uniform', 'distance']}]\n",
    "\n",
    "    model = GridSearchCV(estimator=pipe_svc,param_grid=param_grid, cv = 5, return_train_score=True, n_jobs = -1)\n",
    "    model.fit(x_train, y_train)\n",
    "    return model\n",
    "\n",
    "def train_linear_svm(x_train, y_train):\n",
    "    # Define simple pipeline\n",
    "    pipe_svc = Pipeline((\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"clf\", SVC())\n",
    "    ))\n",
    "    # Establish params\n",
    "    param_grid = [#{'clf__kernel': ['linear'], 'clf__C': [0.1,1,10,100]},\n",
    "                 {'clf__kernel': ['rbf'], 'clf__gamma': [1e-1,1e-2, 1e-3, 1e-4], 'clf__C': [0.01,0.1,1,10, 100,1000]}]\n",
    "\n",
    "    model = GridSearchCV(estimator=pipe_svc,param_grid=param_grid, cv = 5, return_train_score=True, n_jobs = -1)\n",
    "    model.fit(x_train, y_train)\n",
    "    return model\n",
    "\n",
    "def read_last_results(file, ncolumns, npatients):\n",
    "    if os.path.isfile(file):\n",
    "        past_df = pd.read_csv(file, delimiter=',')\n",
    "    else:\n",
    "        zero_data = np.zeros([npatients, ncolumns])\n",
    "        past_df = pd.DataFrame(zero_data, columns = column_names)\n",
    "    return past_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = ['chb01', 'chb02', 'chb03', 'chb04', 'chb05', 'chb07', 'chb08', 'chb09','chb10', 'chb11',\n",
    "            'chb13', 'chb14', 'chb15', 'chb16', 'chb17', 'chb18', 'chb19', 'chb20', 'chb21', 'chb22', 'chb23']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- Finished report for patient chb01 -----------------------\n",
      "---------------------- Finished report for patient chb02 -----------------------\n",
      "---------------------- Finished report for patient chb03 -----------------------\n",
      "---------------------- Finished report for patient chb04 -----------------------\n",
      "---------------------- Finished report for patient chb05 -----------------------\n",
      "---------------------- Finished report for patient chb07 -----------------------\n",
      "---------------------- Finished report for patient chb08 -----------------------\n",
      "---------------------- Finished report for patient chb09 -----------------------\n",
      "---------------------- Finished report for patient chb10 -----------------------\n",
      "---------------------- Finished report for patient chb11 -----------------------\n",
      "---------------------- Finished report for patient chb13 -----------------------\n",
      "---------------------- Finished report for patient chb14 -----------------------\n",
      "---------------------- Finished report for patient chb15 -----------------------\n",
      "---------------------- Finished report for patient chb16 -----------------------\n",
      "---------------------- Finished report for patient chb17 -----------------------\n",
      "---------------------- Finished report for patient chb18 -----------------------\n",
      "---------------------- Finished report for patient chb19 -----------------------\n",
      "---------------------- Finished report for patient chb20 -----------------------\n",
      "---------------------- Finished report for patient chb21 -----------------------\n",
      "---------------------- Finished report for patient chb22 -----------------------\n",
      "---------------------- Finished report for patient chb23 -----------------------\n"
     ]
    }
   ],
   "source": [
    "nchannels = 1\n",
    "column_names = ['patient', 'model', 'hyperparameters', 'sensitivity', 'specificity', 'roc_auc', 'precision', 'accuracy']\n",
    "\n",
    "past_df_svm = read_last_results(basedir + '\\\\results_prediction\\\\svm_rbf_' + str(nchannels) + 'channels.csv', len(column_names), len(patients))\n",
    "past_df_rnf = read_last_results(basedir + '\\\\results_prediction\\\\rnf_' + str(nchannels) + 'channels.csv', len(column_names), len(patients))\n",
    "past_df_knn = read_last_results(basedir + '\\\\results_prediction\\\\knn_' + str(nchannels) + 'channels.csv', len(column_names), len(patients))\n",
    "\n",
    "# Open file to store the results in a txt format, more detailed than the csv\n",
    "f = open(basedir + '\\\\results_prediction\\\\results' + str(nchannels) + 'channels.txt',\"w+\")\n",
    "\n",
    "data_svm = np.zeros(8)\n",
    "data_rnf = np.zeros(8)\n",
    "data_knn = np.zeros(8)\n",
    "for i, patient in enumerate(patients):\n",
    "    # Calculate most significant channels for patient\n",
    "    channelsdf = pd.read_csv('..\\DataSetCreation\\DataSetsPrediction\\\\' + patient + '_channel_order.csv', delimiter=',')\n",
    "    best_channels = get_best_channels(channelsdf, nchannels)\n",
    "    \n",
    "    # Read the patient dataframe\n",
    "    df = pd.read_hdf('..\\DataSetCreation\\DataSetsPrediction\\\\' + patient + 'features.h5', key = 'fullpatient')\n",
    "    \n",
    "    # Extract only the best channels\n",
    "    df = eval(get_expression(best_channels))\n",
    "    df = df.drop(['channel'], axis=1)\n",
    "    \n",
    "    # Split the dataframe into train and test\n",
    "    x_train, y_train, x_test, y_test = split_proportional(df, 0.2, 'seizure')\n",
    "    \n",
    "    # Encode the seizure labels\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(y_train)\n",
    "    y_train_encoded = le.transform(y_train)\n",
    "    y_test_encoded = le.transform(y_test)\n",
    "    # Make 1hot encoder for recall measure\n",
    "    onehot = preprocessing.OneHotEncoder()\n",
    "    onehot.fit(y_test_encoded.reshape(-1,1))\n",
    "    y_test_1hot = onehot.transform(y_test_encoded.reshape(-1,1))\n",
    "    \n",
    "    # Train models\n",
    "    svc_clf = train_linear_svm(x_train, y_train_encoded)\n",
    "    rnf_clf = train_random_forest(x_train, y_train_encoded)\n",
    "    knn_clf = train_knn(x_train, y_train_encoded)\n",
    "    \n",
    "    # Results for SVM model\n",
    "    y_train_pred = svc_clf.predict(x_train)\n",
    "    y_true, y_pred = y_test_encoded, svc_clf.predict(x_test)\n",
    "    y_pred_1hot = onehot.transform(y_pred.reshape(-1,1))\n",
    "    \n",
    "    \n",
    "    f.write('-------------------------- Patient ' + patient + ' ------------------------------------\\n')\n",
    "    f.write(str(svc_clf.best_params_) + '\\n')\n",
    "    \n",
    "    # Predict and see final model\n",
    "    f.write(classification_report(y_train_encoded, y_train_pred) + '\\n')\n",
    "    f.write(classification_report(y_true, y_pred) + '\\n')\n",
    "    \n",
    "    print('---------------------- Finished report for patient ' + patient + ' -----------------------')\n",
    "    f.write('---------------------- Finished report for patient ' + patient + ' -----------------------\\n\\n\\n')\n",
    "    \n",
    "    # Add result to the csv file\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sensitivity = cm[1][1]/(cm[1][1] + cm[1][0])\n",
    "    specificity = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "    precision = cm[1][1]/(cm[1][1] + cm[0][1])\n",
    "    roc_score = roc_auc_score(y_test_1hot.toarray(), y_pred_1hot.toarray(), multi_class=\"ovo\", average=\"weighted\")\n",
    "    accuracy = (cm[0][0]+cm[1][1])/(sum(cm))\n",
    "    \n",
    "    # Replace if better results\n",
    "    if (sensitivity + specificity )/2 > (past_df_svm.iloc[i]['sensitivity'] + past_df_svm.iloc[i]['specificity'])/2:\n",
    "        data_svm = np.vstack((data_svm, np.array([patient, 'svm_rbf', str(svc_clf.best_params_), sensitivity, specificity, roc_score, precision, accuracy])))\n",
    "    else: \n",
    "        data_svm = np.vstack((data_svm, past_df_svm.iloc[i].values))\n",
    "        \n",
    "    # Results for RandomForest model\n",
    "    y_train_pred = rnf_clf.predict(x_train)\n",
    "    y_true, y_pred = y_test_encoded, rnf_clf.predict(x_test)\n",
    "    y_pred_1hot = onehot.transform(y_pred.reshape(-1,1))\n",
    "    \n",
    "    # Add result to the csv file\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sensitivity = cm[1][1]/(cm[1][1] + cm[1][0])\n",
    "    specificity = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "    precision = cm[1][1]/(cm[1][1] + cm[0][1])\n",
    "    roc_score = roc_auc_score(y_test_1hot.toarray(), y_pred_1hot.toarray(), multi_class=\"ovo\", average=\"weighted\")\n",
    "    accuracy = (cm[0][0]+cm[1][1])/(sum(cm))\n",
    "    \n",
    "    # Replace if better results\n",
    "    if (sensitivity + specificity )/2 > (past_df_rnf.iloc[i]['sensitivity'] + past_df_rnf.iloc[i]['specificity'])/2:\n",
    "        data_rnf = np.vstack((data_rnf, np.array([patient, 'rnf', str(rnf_clf.best_params_), sensitivity, specificity, roc_score, precision, accuracy])))\n",
    "    else: \n",
    "        data_rnf = np.vstack((data_rnf, past_df_rnf.iloc[i].values))\n",
    "        \n",
    "    # Results for KNN model\n",
    "    y_train_pred = knn_clf.predict(x_train)\n",
    "    y_true, y_pred = y_test_encoded, knn_clf.predict(x_test)\n",
    "    y_pred_1hot = onehot.transform(y_pred.reshape(-1,1))\n",
    "    \n",
    "    # Add result to the csv file\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sensitivity = cm[1][1]/(cm[1][1] + cm[1][0])\n",
    "    specificity = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "    precision = cm[1][1]/(cm[1][1] + cm[0][1])\n",
    "    roc_score = roc_auc_score(y_test_1hot.toarray(), y_pred_1hot.toarray(), multi_class=\"ovo\", average=\"weighted\")\n",
    "    accuracy = (cm[0][0]+cm[1][1])/(sum(cm))\n",
    "    \n",
    "    # Replace if better results\n",
    "    if (sensitivity + specificity )/2 > (past_df_knn.iloc[i]['sensitivity'] + past_df_knn.iloc[i]['specificity'])/2:\n",
    "        data_knn = np.vstack((data_knn, np.array([patient, 'knn', str(knn_clf.best_params_), sensitivity, specificity, roc_score, precision, accuracy])))\n",
    "    else: \n",
    "        data_knn = np.vstack((data_knn, past_df_knn.iloc[i].values))\n",
    "    \n",
    "    \n",
    "        \n",
    "# Close  text file\n",
    "f.close() \n",
    "\n",
    "# Save df to csv file\n",
    "data_svm = data_svm[1:, :]\n",
    "dataframe_svm = pd.DataFrame(data_svm, columns = column_names)\n",
    "dataframe_svm.set_index('patient')\n",
    "dataframe_svm.to_csv(basedir + '\\\\results_prediction\\\\svm_rbf_' + str(nchannels) + 'channels.csv', index=False)\n",
    "\n",
    "# Save df to csv file\n",
    "data_rnf = data_rnf[1:, :]\n",
    "dataframe_rnf = pd.DataFrame(data_rnf, columns = column_names)\n",
    "dataframe_rnf.set_index('patient')\n",
    "dataframe_rnf.to_csv(basedir + '\\\\results_prediction\\\\rnf_' + str(nchannels) + 'channels.csv', index=False)\n",
    "\n",
    "# Save df to csv file\n",
    "data_knn = data_knn[1:, :]\n",
    "dataframe_knn = pd.DataFrame(data_knn, columns = column_names)\n",
    "dataframe_knn.set_index('patient')\n",
    "dataframe_knn.to_csv(basedir + '\\\\results_prediction\\\\knn_' + str(nchannels) + 'channels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
