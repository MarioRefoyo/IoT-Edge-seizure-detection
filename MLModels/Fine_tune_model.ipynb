{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "import glob, os\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = os.getcwd()\n",
    "os.chdir(basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_channels(channelsdf, nchannels=2):\n",
    "    \n",
    "    list_of_rows = [list(row) for row in channelsdf.values]\n",
    "    \n",
    "    channel_score_dict = {}\n",
    "    for i, elem in enumerate(list_of_rows[0]):\n",
    "        channel_score_dict[elem] = i\n",
    "\n",
    "    for row, rowlist in enumerate(list_of_rows[1:]):\n",
    "        for i, elem in enumerate(rowlist):\n",
    "            channel_score_dict[elem] = channel_score_dict[elem] + i\n",
    "\n",
    "    sorted_channels = sorted(channel_score_dict, key=channel_score_dict.get)\n",
    "    best_channels = sorted_channels[:nchannels]\n",
    "    \n",
    "    return best_channels\n",
    "\n",
    "def get_expression(channels):\n",
    "    expression = 'df['\n",
    "    for channel in best_channels:\n",
    "        expression +='(df[\\'channel\\'] == \\'' + channel + '\\')|'\n",
    "    return expression[:-1] + ']'\n",
    "\n",
    "def split_train_test(data, test_ratio):\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_set = data.iloc[:test_set_size]\n",
    "    train_set = data.iloc[test_set_size:]\n",
    "    return train_set, test_set\n",
    "\n",
    "def split_proportional(dataframe, test_ratio, target):\n",
    "    \n",
    "    df_seizures = dataframe[dataframe[target] == True]\n",
    "    df_normal = dataframe[dataframe[target] == False]\n",
    "    \n",
    "    train_seizures, test_seizures = split_train_test(df_seizures, test_ratio)\n",
    "    train_normal, test_normal = split_train_test(df_normal, test_ratio)\n",
    "    \n",
    "    df_train = pd.concat([train_normal, train_seizures], axis=0).reset_index()\n",
    "    x_train, y_train = df_train[df_train.columns.difference([target])], df_train[target]\n",
    "    df_test = pd.concat([test_normal, test_seizures], axis=0).reset_index()\n",
    "    x_test, y_test = df_test[df_test.columns.difference([target])], df_test[target]\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def read_last_results(file, ncolumns):\n",
    "    if os.path.isfile('svm_rbf_' + str(nchannels) + 'channels.csv'):\n",
    "        past_df = pd.read_csv('svm_rbf_' + str(nchannels) + 'channels.csv', delimiter=',')\n",
    "    else:\n",
    "        zero_data = np.zeros([len(patients), ncolumns])\n",
    "        past_df = pd.DataFrame(zero_data, columns = column_names)\n",
    "    return past_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = 'chb07'\n",
    "nchannels = 1\n",
    "column_names = ['patient', 'model', 'hyperparameters', 'sensitivity', 'specificity', 'roc_auc', 'precision', 'accuracy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['F3-C3']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate most significant channels for patient\n",
    "channelsdf = pd.read_csv('..\\DataSetCreation\\Datasets\\\\' + patient + '_channel_order.csv', delimiter=',')\n",
    "best_channels = get_best_channels(channelsdf, nchannels)\n",
    "best_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the results last dataframe and extracts the row\n",
    "past_df = read_last_results(basedir + '\\\\results_normal\\\\svm_rbf_' + str(nchannels) + 'channels.csv', len(column_names))\n",
    "past_patient_data = past_df[past_df['patient'] == patient]\n",
    "pos = past_patient_data.index[0]\n",
    "\n",
    "# Calculate most significant channels for patient\n",
    "channelsdf = pd.read_csv('..\\DataSetCreation\\Datasets\\\\' + patient + '_channel_order.csv', delimiter=',')\n",
    "best_channels = get_best_channels(channelsdf, nchannels)\n",
    "    \n",
    "# Read the patient dataframe\n",
    "df = pd.read_hdf('..\\DataSetCreation\\Datasets\\\\' + patient + 'features.h5', key = 'fullpatient')\n",
    "\n",
    "# Extract only the best channels\n",
    "df = eval(get_expression(best_channels))\n",
    "df = df.drop(['channel'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataframe into train and test\n",
    "x_train, y_train, x_test, y_test = split_proportional(df, 0.2, 'seizure')\n",
    "\n",
    "C = 5\n",
    "gamma = 0.01\n",
    "kernel = 'rbf'\n",
    "max_iter = 100000000\n",
    "#params = '(C: {}, gamma: {})'.format(C, gamma)\n",
    "params = {'clf__C': C, 'clf__gamma': gamma, 'clf__kernel': kernel}\n",
    "\n",
    "# Train models\n",
    "svm_clf = Pipeline((\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"linear_svc\", SVC(kernel = kernel, C=C, gamma = gamma, max_iter = max_iter))\n",
    "))\n",
    "svm_clf.fit(x_train, y_train)\n",
    "\n",
    "#y_scores = svm_clf.decision_function()\n",
    "\n",
    "y_train_pred = cross_val_predict(svm_clf, x_train, y_train, cv=5, n_jobs = 12)\n",
    "\n",
    "# Predict\n",
    "y_train_pred = svm_clf.predict(x_train)\n",
    "y_true, y_pred = y_test, svm_clf.predict(x_test)\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sensitivity = cm[1][1]/(cm[1][1] + cm[1][0])\n",
    "specificity = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "precision = cm[1][1]/(cm[1][1] + cm[0][1])\n",
    "roc_score = roc_auc_score(y_true, y_pred)\n",
    "accuracy = (cm[0][0]+cm[1][1])/(sum(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score: 1.0\n",
      "Recall score: 1.0\n",
      "F1 score: 1.0\n",
      "Roc_auc score: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Precision score: ' + str(precision_score(y_train, y_train_pred)))\n",
    "print('Recall score: ' + str(recall_score(y_train, y_train_pred)))\n",
    "print('F1 score: ' + str(f1_score(y_train, y_train_pred)))\n",
    "print('Roc_auc score: ' + str(roc_auc_score(y_train, y_train_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity score: 0.2727272727272727\n",
      "Specificity score: 0.999244142101285\n",
      "Precision score: 0.75\n",
      "Roc_auc score: 0.6359857074142788\n",
      "Accuracy: 0.9932533733133433\n"
     ]
    }
   ],
   "source": [
    "print('Sensitivity score: ' + str(sensitivity))\n",
    "print('Specificity score: ' + str(specificity))\n",
    "print('Precision score: ' + str(precision))\n",
    "print('Roc_auc score: ' + str(roc_score))\n",
    "print('Accuracy: ' + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better results than before\n"
     ]
    }
   ],
   "source": [
    "# Replace if better results\n",
    "if (sensitivity + specificity )/2 > (past_patient_data['sensitivity'].values[0] + past_patient_data['specificity'].values[0])/2:\n",
    "    print('Better results than before')\n",
    "    data = np.array([patient, 'svm_rbf', params, sensitivity, specificity, roc_score, precision, accuracy])\n",
    "    \n",
    "    aux_array = past_df.to_numpy()\n",
    "    aux_array[pos] = data\n",
    "    new_df = pd.DataFrame(aux_array, columns = column_names)\n",
    "    # Save new results\n",
    "    new_df.to_csv(basedir + '\\\\results_normal\\\\svm_rbf_' + str(nchannels) + 'channels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
