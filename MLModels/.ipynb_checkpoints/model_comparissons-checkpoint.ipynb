{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "import glob, os\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = os.getcwd()\n",
    "os.chdir(basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_channels(channelsdf, nchannels=2):\n",
    "    \n",
    "    list_of_rows = [list(row) for row in channelsdf.values]\n",
    "    \n",
    "    channel_score_dict = {}\n",
    "    for i, elem in enumerate(list_of_rows[0]):\n",
    "        channel_score_dict[elem] = i\n",
    "\n",
    "    for row, rowlist in enumerate(list_of_rows[1:]):\n",
    "        for i, elem in enumerate(rowlist):\n",
    "            channel_score_dict[elem] = channel_score_dict[elem] + i\n",
    "\n",
    "    sorted_channels = sorted(channel_score_dict, key=channel_score_dict.get)\n",
    "    best_channels = sorted_channels[:nchannels]\n",
    "    \n",
    "    return best_channels\n",
    "\n",
    "def get_expression(channels):\n",
    "    expression = 'df['\n",
    "    for channel in best_channels:\n",
    "        expression +='(df[\\'channel\\'] == \\'' + channel + '\\')|'\n",
    "    return expression[:-1] + ']'\n",
    "\n",
    "def split_train_test(data, test_ratio):\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_set = data.iloc[:test_set_size]\n",
    "    train_set = data.iloc[test_set_size:]\n",
    "    return train_set, test_set\n",
    "\n",
    "def split_proportional(dataframe, test_ratio, target):\n",
    "    \n",
    "    df_seizures = dataframe[dataframe[target] == True]\n",
    "    df_normal = dataframe[dataframe[target] == False]\n",
    "    \n",
    "    train_seizures, test_seizures = split_train_test(df_seizures, test_ratio)\n",
    "    train_normal, test_normal = split_train_test(df_normal, test_ratio)\n",
    "    \n",
    "    df_train = pd.concat([train_normal, train_seizures], axis=0).reset_index()\n",
    "    x_train, y_train = df_train[df_train.columns.difference([target])], df_train[target]\n",
    "    df_test = pd.concat([test_normal, test_seizures], axis=0).reset_index()\n",
    "    x_test, y_test = df_test[df_test.columns.difference([target])], df_test[target]\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "def train_linear_svm(x_train, y_train, scorers):\n",
    "    # Define simple pipeline\n",
    "    pipe_svc = Pipeline((\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"clf\", SVC())\n",
    "    ))\n",
    "    # Establish params\n",
    "    param_grid = [#{'clf__kernel': ['linear'], 'clf__C': [0.1,1,10,100]},\n",
    "                 {'clf__kernel': ['rbf'], 'clf__gamma': [1e-1,1e-2, 1e-3, 1e-4], 'clf__C': [0.01,0.1,1,10, 100, 1000]}]\n",
    "\n",
    "    model = GridSearchCV(estimator=pipe_svc,param_grid=param_grid, cv = 5, scoring=make_scorer(roc_auc_score), return_train_score=True, n_jobs = -1)\n",
    "    model.fit(x_train, y_train)\n",
    "    return model\n",
    "\n",
    "def read_last_results(file, ncolumns):\n",
    "    if os.path.isfile('svm_rbf_' + str(nchannels) + 'channels.csv'):\n",
    "        past_df = pd.read_csv('svm_rbf_' + str(nchannels) + 'channels.csv', delimiter=',')\n",
    "    else:\n",
    "        zero_data = np.zeros([len(patients), ncolumns])\n",
    "        past_df = pd.DataFrame(zero_data, columns = column_names)\n",
    "    return past_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = ['chb01', 'chb02', 'chb03', 'chb05', 'chb07', 'chb08', 'chb09','chb10', 'chb11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- Finished report for patient chb01 -----------------------\n",
      "---------------------- Finished report for patient chb02 -----------------------\n",
      "---------------------- Finished report for patient chb03 -----------------------\n",
      "---------------------- Finished report for patient chb05 -----------------------\n",
      "---------------------- Finished report for patient chb07 -----------------------\n",
      "---------------------- Finished report for patient chb08 -----------------------\n",
      "---------------------- Finished report for patient chb09 -----------------------\n",
      "---------------------- Finished report for patient chb10 -----------------------\n",
      "---------------------- Finished report for patient chb11 -----------------------\n"
     ]
    }
   ],
   "source": [
    "nchannels = 1\n",
    "column_names = ['patient', 'model', 'hyperparameters', 'sensitivity', 'specificity', 'roc_auc', 'precision', 'accuracy']\n",
    "\n",
    "past_df = read_last_results('svm_rbf_' + str(nchannels) + 'channels.csv', len(column_names))\n",
    "\n",
    "# Open file to store the results in a txt format, more detailed than the csv\n",
    "f = open(basedir + '\\\\results' + str(nchannels) + 'channels.txt',\"w+\")\n",
    "\n",
    "text = ''\n",
    "data = np.zeros(8)\n",
    "for i, patient in enumerate(patients):\n",
    "    # Calculate most significant channels for patient\n",
    "    channelsdf = pd.read_csv('..\\DataSetCreation\\Datasets\\\\' + patient + '_channel_order.csv', delimiter=',')\n",
    "    best_channels = get_best_channels(channelsdf, nchannels)\n",
    "    \n",
    "    # Read the patient dataframe\n",
    "    df = pd.read_hdf('..\\DataSetCreation\\Datasets\\\\' + patient + 'features.h5', key = 'fullpatient')\n",
    "    \n",
    "    # Extract only the best channels\n",
    "    df = eval(get_expression(best_channels))\n",
    "    df = df.drop(['channel'], axis=1)\n",
    "    \n",
    "    # Split the dataframe into train and test\n",
    "    x_train, y_train, x_test, y_test = split_proportional(df, 0.2, 'seizure')\n",
    "    \n",
    "    # Train models\n",
    "    svc_clf = train_linear_svm(x_train, y_train, scorers)\n",
    "    \n",
    "    f.write('-------------------------- Patient ' + patient + ' ------------------------------------\\n')\n",
    "    f.write(str(svc_clf.best_params_) + '\\n')\n",
    "    \n",
    "    # Predict and see final model\n",
    "    y_train_pred = svc_clf.predict(x_train)\n",
    "    f.write(classification_report(y_train, y_train_pred) + '\\n')\n",
    "    y_true, y_pred = y_test, svc_clf.predict(x_test)\n",
    "    f.write(classification_report(y_true, y_pred) + '\\n')\n",
    "    \n",
    "    print('---------------------- Finished report for patient ' + patient + ' -----------------------')\n",
    "    f.write('---------------------- Finished report for patient ' + patient + ' -----------------------\\n\\n\\n')\n",
    "    \n",
    "    # Add result to the csv file\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sensitivity = cm[1][1]/(cm[1][1] + cm[1][0])\n",
    "    specificity = cm[0][0]/(cm[0][0] + cm[0][1])\n",
    "    precision = cm[1][1]/(cm[1][1] + cm[0][1])\n",
    "    roc_score = roc_auc_score(y_true, y_pred)\n",
    "    accuracy = (cm[0][0]+cm[1][1])/(sum(cm))\n",
    "    \n",
    "    # Replace if better results\n",
    "    if (sensitivity + specificity + precision)/3 > (past_df.iloc[i]['sensitivity'] + past_df.iloc[i]['specificity'] + past_df.iloc[i]['precision'])/3:\n",
    "        data = np.vstack((data, np.array([patient, 'svm_rbf', str(svc_clf.best_params_), sensitivity, specificity, precision, roc_score, accuracy])))\n",
    "    else: \n",
    "        data = np.vstack((data, past_df.iloc[i].values))\n",
    "        \n",
    "# Close  text file\n",
    "f.close() \n",
    "\n",
    "# Save df to csv file\n",
    "data = data[1:, :]\n",
    "dataframe = pd.DataFrame(data, columns = column_names)\n",
    "dataframe.set_index('patient')\n",
    "dataframe.to_csv('svm_rbf_' + str(nchannels) + 'channels.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tune patient model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = 'chb08'\n",
    "nchannels = 1\n",
    "column_names = ['patient', 'model', 'hyperparameters', 'sensitivity', 'specificity', 'roc_auc', 'precision', 'accuracy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the results last dataframe and extracts the row\n",
    "past_df = read_last_results('svm_rbf_' + str(nchannels) + 'channels.csv', len(column_names))\n",
    "past_patient_data = past_df[past_df['patient'] == patient].values\n",
    "\n",
    "# Calculate most significant channels for patient\n",
    "channelsdf = pd.read_csv('..\\DataSetCreation\\Datasets\\\\' + patient + '_channel_order.csv', delimiter=',')\n",
    "best_channels = get_best_channels(channelsdf, nchannels)\n",
    "    \n",
    "# Read the patient dataframe\n",
    "df = pd.read_hdf('..\\DataSetCreation\\Datasets\\\\' + patient + 'features.h5', key = 'fullpatient')\n",
    "\n",
    "# Extract only the best channels\n",
    "df = eval(get_expression(best_channels))\n",
    "df = df.drop(['channel'], axis=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataframe into train and test\n",
    "x_train, y_train, x_test, y_test = split_proportional(df, 0.2, 'seizure')\n",
    "\n",
    "# Train models\n",
    "svm_clf = Pipeline((\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"linear_svc\", svm.SVC(kernel = 'rbf', C=100, gamma = 0.01, max_iter = 100000000))\n",
    "))\n",
    "svm_clf.fit(x_train, y_train)\n",
    "\n",
    "#y_scores = svm_clf.decision_function()\n",
    "\n",
    "y_train_pred = cross_val_predict(svm_clf, x_train, y_train, cv=5, n_jobs = 12)\n",
    "\n",
    "# Predict\n",
    "y_train_pred = svm_clf.predict(x_train)\n",
    "y_true, y_pred = y_test, svm_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score: 0.9621993127147767\n",
      "Recall score: 0.7650273224043715\n",
      "F1 score: 0.852359208523592\n",
      "Roc_auc score: 0.8817089794172553\n"
     ]
    }
   ],
   "source": [
    "print('Precision score: ' + str(precision_score(y_train, y_train_pred)))\n",
    "print('Recall score: ' + str(recall_score(y_train, y_train_pred)))\n",
    "print('F1 score: ' + str(f1_score(y_train, y_train_pred)))\n",
    "print('Roc_auc score: ' + str(roc_auc_score(y_train, y_train_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      1.00      0.99      6835\n",
      "        True       0.96      0.77      0.85       366\n",
      "\n",
      "    accuracy                           0.99      7201\n",
      "   macro avg       0.97      0.88      0.92      7201\n",
      "weighted avg       0.99      0.99      0.99      7201\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.99      0.99      1708\n",
      "        True       0.86      0.68      0.76        91\n",
      "\n",
      "    accuracy                           0.98      1799\n",
      "   macro avg       0.92      0.84      0.87      1799\n",
      "weighted avg       0.98      0.98      0.98      1799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_train_pred))\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
