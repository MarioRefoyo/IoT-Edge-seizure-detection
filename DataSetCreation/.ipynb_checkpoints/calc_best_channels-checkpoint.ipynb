{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyedflib\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "import glob, os\n",
    "from collections import OrderedDict\n",
    "from scipy.stats import *\n",
    "import csv\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing, Holt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = os.getcwd()\n",
    "# Put here the directory of the CHBMIT DATABASE\n",
    "dbdir = r\"F:\\Master\\TFM\\chb-mit-scalp-eeg-database-1.0.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Register:\n",
    "    \n",
    "    def __init__(self, name, fs, nseizures):\n",
    "        self.name = name\n",
    "        self.fs = fs\n",
    "        self.nseizures = nseizures\n",
    "        self.seizures = []\n",
    "        self.channels = []\n",
    "            \n",
    "    def addSeizure (self, start, end):\n",
    "        seizure = [start, end]\n",
    "        self.seizures.append(seizure)\n",
    "        \n",
    "    def addCh (self, channels):\n",
    "        self.channels = channels\n",
    "\n",
    "def read_data(filename, channels=[]):\n",
    "    f = pyedflib.EdfReader(filename)\n",
    "    if len(channels) == 0:\n",
    "        channels = f.getSignalLabels()\n",
    "\n",
    "    channel_names = f.getSignalLabels()\n",
    "    fs = f.getSampleFrequencies()\n",
    "\n",
    "    data = np.zeros((len(channels), f.getNSamples()[0]))\n",
    "    for i, channel in enumerate(channels):\n",
    "        data[i, :] = f.readSignal(channel_names.index(channel))\n",
    "        \n",
    "    time = np.linspace(0, data.shape[1]/fs[0], data.shape[1])\n",
    "    f._close()\n",
    "    return data, fs[0], time\n",
    "\n",
    "def trunc(data, timeW, fs):\n",
    "    samples = data.shape[1]\n",
    "    timeW = 2\n",
    "    N = timeW*fs\n",
    "    nw = int(samples//N)\n",
    "\n",
    "    data = data [:, 0:nw*N]\n",
    "    time = np.linspace(0, data.shape[1]/fs, data.shape[1])\n",
    "    return data, time, nw, N\n",
    "\n",
    "def calc_variances_entropys(signals, nw, N):\n",
    "    variances = np.zeros([signals.shape[0], nw])\n",
    "    entropys = np.zeros([signals.shape[0], nw])\n",
    "    for channel, signal in enumerate(signals):\n",
    "        signal = np.reshape(signal, [nw, N])\n",
    "        variances[channel, :] = np.var(signal, 1)\n",
    "        for n, s in enumerate(signal):\n",
    "            pd_series = pd.Series(s)\n",
    "            counts = pd_series.value_counts()\n",
    "            entropys[channel, n] = entropy(counts, base = 2)\n",
    "    return variances, entropys\n",
    "\n",
    "\n",
    "def select_best_signals(signals_trunc, nw, N, seizureW, nchannels, channel_index):\n",
    "    \n",
    "    channel_index = {y:x for x,y in channel_index.items()}\n",
    "    \n",
    "    variances, entropys = calc_variances_entropys(signals_trunc, nw, N)\n",
    "    \n",
    "    nictal_index = list(range(nw))\n",
    "    ictal_index = where(seizureW == 1)[0]\n",
    "    [nictal_index.remove(i) for i in ictal_index]\n",
    "    \n",
    "    i_variances = np.take(variances, ictal_index, axis=1)\n",
    "    ni_variances = np.take(variances, nictal_index, axis=1)\n",
    "    i_entropys = np.take(variances, ictal_index, axis=1)\n",
    "    ni_entropys = np.take(variances, nictal_index, axis=1)\n",
    "          \n",
    "    score = (mean(i_variances, axis = 1) - mean(ni_variances, axis = 1)) * (mean(i_entropys, axis = 1) - mean(ni_entropys, axis = 1))\n",
    "    \n",
    "    dictionary = dict(zip(channel_index.keys(), score))\n",
    "    sorted_dict = {k: v for k, v in sorted(dictionary.items(), key=lambda item: item[1], reverse=True)}\n",
    "    \n",
    "    # order the channels by significance\n",
    "    significant_channels = list(sorted_dict.keys())[0:nchannels]\n",
    "    significant_signals = zeros([len(significant_channels), signals_trunc.shape[1]])\n",
    "    for i, key in enumerate(significant_channels):\n",
    "        significant_signals[i, :] = signals_trunc[channel_index[key], :]\n",
    "        \n",
    "    return significant_signals, significant_channels\n",
    "\n",
    "def select_best_signals2(signals_trunc, nw, N, seizureW, nchannels, channel_index):\n",
    "    \n",
    "    channel_index = {y:x for x,y in channel_index.items()}\n",
    "    \n",
    "    variances, entropys = calc_variances_entropys(signals_trunc, nw, N)\n",
    "    \n",
    "    ictal_index = where(seizureW == 1)[0]\n",
    "    \n",
    "    i_variances = np.take(variances, ictal_index, axis=1)\n",
    "    i_entropys = np.take(variances, ictal_index, axis=1)\n",
    "          \n",
    "    score = mean(i_variances, axis = 1) * mean(i_entropys, axis = 1)\n",
    "    \n",
    "    dictionary = dict(zip(channel_index.keys(), score))\n",
    "    sorted_dict = {k: v for k, v in sorted(dictionary.items(), key=lambda item: item[1], reverse=True)}\n",
    "    \n",
    "    # order the channels by significance\n",
    "    significant_channels = list(sorted_dict.keys())[0:nchannels]\n",
    "    significant_signals = zeros([len(significant_channels), signals_trunc.shape[1]])\n",
    "    for i, key in enumerate(significant_channels):\n",
    "        significant_signals[i, :] = signals_trunc[channel_index[key], :]\n",
    "        \n",
    "    return significant_signals, significant_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_annotations(annotation):\n",
    "    with open(annotation) as f:\n",
    "        registers = {}\n",
    "        channels_dict = {}\n",
    "        nmontages = 1\n",
    "        for line in f:\n",
    "            if (\"Data Sampling Rate\" in line):\n",
    "                line = line.split()\n",
    "                fs = int(line[3]) \n",
    "                \n",
    "            if (\"Channel \" in line):\n",
    "                line = line.split()\n",
    "                channel = line[2]\n",
    "                if channel in channels_dict:\n",
    "                    channels_dict.update({channel: channels_dict[channel]+1})\n",
    "                else:\n",
    "                    channels_dict[channel] = 1\n",
    "\n",
    "            if (\"Channels changed\" in line):\n",
    "                nmontages += 1\n",
    "                \n",
    "            elif (\"File Name\" in line):\n",
    "                name = line.split()[2]\n",
    "                while True:\n",
    "                    newLine = f.readline()\n",
    "                    if (\"Number of Seizures\" in newLine):\n",
    "                        nseizures = int(newLine.split()[5])\n",
    "                        register = Register(name, fs, nseizures)\n",
    "                        if nseizures > 0:\n",
    "                            for i in range(nseizures):\n",
    "                                line1 = f.readline().split()\n",
    "                                line2 = f.readline().split()\n",
    "                                if (line1[3] == \"Time:\"):\n",
    "                                    start = int(line1[4])\n",
    "                                    end = int(line2[4])\n",
    "                                else:\n",
    "                                    start = int(line1[3])\n",
    "                                    end = int(line2[3])\n",
    "                                register.addSeizure(start, end)\n",
    "\n",
    "                        registers[name] = register\n",
    "                        break\n",
    "    common_channels = []\n",
    "    [common_channels.append(key) for key in channels_dict.keys() if channels_dict[key] == nmontages]\n",
    "    channel_index = dict(zip( list(np.arange(len(common_channels))), common_channels ))\n",
    "    return registers, channel_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset creation for all the patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = os.getcwd()\n",
    "datasetdir = basedir + '\\DatasetsSinExp'\n",
    "\n",
    "# Put here the directory of the CHBMIT DATABASE\n",
    "dbdir = r\"F:\\Master\\TFM\\chb-mit-scalp-eeg-database-1.0.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(dbdir)\n",
    "patients = [name for name in os.listdir(\".\") if os.path.isdir(name)]\n",
    "patients = patients[11:]\n",
    "patients = ['chb04']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(dbdir + '\\RECORDS-WITH-SEIZURES', 'r', encoding = 'utf-8')\n",
    "seizure_files = f.read().split('\\n')\n",
    "seizure_files = list(map(lambda string: string[6:], seizure_files))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------- Patient: chb04 ----------------------------------------------------\n",
      "Readed chb04_05.edf\n",
      "Readed chb04_08.edf\n",
      "Readed chb04_28.edf\n"
     ]
    }
   ],
   "source": [
    "timeW = 2\n",
    "decimationCoeff = 2\n",
    "\n",
    "for patient in patients:\n",
    "    print('---------------------------------------------- Patient: ' + patient + ' ----------------------------------------------------')\n",
    "    fdir = dbdir + '\\\\' + patient\n",
    "    os.chdir(fdir)\n",
    "    annotation = glob.glob('*txt')\n",
    "    \n",
    "    registers, channel_index = read_annotations(annotation[0])\n",
    "\n",
    "    nchannels = len(channel_index)\n",
    "    selected_channels_lof = []\n",
    "\n",
    "    dataframe = pd.DataFrame()\n",
    "    for key, value in registers.items():\n",
    "\n",
    "        # Signal reading: only if is a seizure file\n",
    "        if key in seizure_files:\n",
    "            signals, originalfs, time = read_data(key, value.channels)\n",
    "            # Decimation\n",
    "            signals = signal.decimate(signals, decimationCoeff)\n",
    "            fs = originalfs//decimationCoeff\n",
    "\n",
    "            # Truncate to generate time windows\n",
    "            signals_trunc, time, nw, N = trunc(signals, timeW, fs)\n",
    "            samples = signals_trunc.shape[1]\n",
    "\n",
    "            print(\"Readed \" + key)\n",
    "\n",
    "            # Seizure vector creation\n",
    "            seizure = zeros(samples)\n",
    "\n",
    "\n",
    "            for n in range (len(value.seizures)):\n",
    "                start = value.seizures[n][0]*fs\n",
    "                end = value.seizures[n][1]*fs\n",
    "                seizure[start:end] = np.ones(end-start)\n",
    "\n",
    "            seizureW = np.reshape(seizure, [nw, N])\n",
    "            seizureW = (sum(seizureW, 1) > N//2)\n",
    "\n",
    "            selected_signals, selected_channels = select_best_signals(signals_trunc, nw, N, seizureW, nchannels, channel_index)\n",
    "            selected_channels_lof.append(selected_channels)\n",
    "\n",
    "            # Create the csv file where the significance order of the selected channels is going to be stored\n",
    "            os.chdir(datasetdir)\n",
    "            f = open(patient + '_channel_order.csv', 'w+')\n",
    "            writer=csv.writer(f)\n",
    "            writer.writerow(list(range(nchannels)))\n",
    "            for item in selected_channels_lof:\n",
    "                writer.writerow(item)\n",
    "            f.close()\n",
    "            os.chdir(fdir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'FP1-F7',\n",
       " 1: 'F7-T7',\n",
       " 2: 'T7-P7',\n",
       " 3: 'P7-O1',\n",
       " 4: 'FP1-F3',\n",
       " 5: 'F3-C3',\n",
       " 6: 'C3-P3',\n",
       " 7: 'P3-O1',\n",
       " 8: 'FZ-CZ',\n",
       " 9: 'CZ-PZ',\n",
       " 10: 'FP2-F4',\n",
       " 11: 'F4-C4',\n",
       " 12: 'C4-P4',\n",
       " 13: 'P4-O2',\n",
       " 14: 'FP2-F8',\n",
       " 15: 'F8-T8',\n",
       " 16: 'P8-O2'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,2,3,4, 5,6, 7,8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_windows(lst, seizure_indexes):\n",
    "    for enumerate\n",
    "    \n",
    "    return (lst[i] for i in indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2 = select(l, [2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,  4, 7],\n",
    "              [2, 5, 8],\n",
    "              [3, 6, 9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7],\n",
       "       [8],\n",
       "       [9]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.take(A, [2], axis=1)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [2],\n",
       "       [3]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = np.take(A, [0], axis = 1)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 5, 7, 8]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [1,2,3,4,5,6,7,8]\n",
    "[l.remove(i) for i in [2,3,6]]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6],\n",
       "       [-6],\n",
       "       [-6]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.array([[1, 2, 3],\n",
    "              [1, 2, 3],\n",
    "              [1, 2, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(Z, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = os.getcwd()\n",
    "datasetdir = basedir + '\\ChannelOrderOnlyIctal'\n",
    "\n",
    "# Put here the directory of the CHBMIT DATABASE\n",
    "dbdir = r\"F:\\Master\\TFM\\chb-mit-scalp-eeg-database-1.0.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chb01',\n",
       " 'chb02',\n",
       " 'chb03',\n",
       " 'chb05',\n",
       " 'chb06',\n",
       " 'chb07',\n",
       " 'chb08',\n",
       " 'chb09',\n",
       " 'chb10',\n",
       " 'chb11',\n",
       " 'chb13',\n",
       " 'chb14',\n",
       " 'chb15',\n",
       " 'chb16',\n",
       " 'chb17',\n",
       " 'chb18',\n",
       " 'chb19',\n",
       " 'chb20',\n",
       " 'chb21',\n",
       " 'chb22',\n",
       " 'chb23',\n",
       " 'chb24']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(dbdir)\n",
    "patients = [name for name in os.listdir(\".\") if os.path.isdir(name)]\n",
    "patients.remove('chb12')\n",
    "patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(dbdir + '\\RECORDS-WITH-SEIZURES', 'r', encoding = 'utf-8')\n",
    "seizure_files = f.read().split('\\n')\n",
    "seizure_files = list(map(lambda string: string[6:], seizure_files))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------- Patient: chb01 ----------------------------------------------------\n",
      "Readed chb01_03.edf\n",
      "Readed chb01_04.edf\n",
      "Readed chb01_15.edf\n",
      "Readed chb01_16.edf\n",
      "Readed chb01_18.edf\n",
      "Readed chb01_21.edf\n",
      "Readed chb01_26.edf\n",
      "---------------------------------------------- Patient: chb02 ----------------------------------------------------\n",
      "Readed chb02_16.edf\n",
      "Readed chb02_19.edf\n",
      "---------------------------------------------- Patient: chb03 ----------------------------------------------------\n",
      "Readed chb03_01.edf\n",
      "Readed chb03_02.edf\n",
      "Readed chb03_03.edf\n",
      "Readed chb03_04.edf\n",
      "Readed chb03_34.edf\n",
      "Readed chb03_35.edf\n",
      "Readed chb03_36.edf\n",
      "---------------------------------------------- Patient: chb05 ----------------------------------------------------\n",
      "Readed chb05_06.edf\n",
      "Readed chb05_13.edf\n",
      "Readed chb05_16.edf\n",
      "Readed chb05_17.edf\n",
      "Readed chb05_22.edf\n",
      "---------------------------------------------- Patient: chb06 ----------------------------------------------------\n",
      "Readed chb06_01.edf\n",
      "Readed chb06_04.edf\n",
      "Readed chb06_09.edf\n",
      "Readed chb06_10.edf\n",
      "Readed chb06_13.edf\n",
      "Readed chb06_18.edf\n",
      "Readed chb06_24.edf\n",
      "---------------------------------------------- Patient: chb07 ----------------------------------------------------\n",
      "Readed chb07_12.edf\n",
      "Readed chb07_13.edf\n",
      "Readed chb07_19.edf\n",
      "---------------------------------------------- Patient: chb08 ----------------------------------------------------\n",
      "Readed chb08_02.edf\n",
      "Readed chb08_05.edf\n",
      "Readed chb08_11.edf\n",
      "Readed chb08_13.edf\n",
      "Readed chb08_21.edf\n",
      "---------------------------------------------- Patient: chb09 ----------------------------------------------------\n",
      "Readed chb09_06.edf\n",
      "Readed chb09_08.edf\n",
      "Readed chb09_19.edf\n",
      "---------------------------------------------- Patient: chb10 ----------------------------------------------------\n",
      "Readed chb10_12.edf\n",
      "Readed chb10_20.edf\n",
      "Readed chb10_27.edf\n",
      "Readed chb10_30.edf\n",
      "Readed chb10_31.edf\n",
      "Readed chb10_38.edf\n",
      "Readed chb10_89.edf\n",
      "---------------------------------------------- Patient: chb11 ----------------------------------------------------\n",
      "Readed chb11_82.edf\n",
      "Readed chb11_92.edf\n",
      "Readed chb11_99.edf\n",
      "---------------------------------------------- Patient: chb13 ----------------------------------------------------\n",
      "Readed chb13_19.edf\n",
      "Readed chb13_21.edf\n",
      "Readed chb13_40.edf\n",
      "Readed chb13_55.edf\n",
      "Readed chb13_58.edf\n",
      "Readed chb13_59.edf\n",
      "Readed chb13_60.edf\n",
      "Readed chb13_62.edf\n",
      "---------------------------------------------- Patient: chb14 ----------------------------------------------------\n",
      "Readed chb14_03.edf\n",
      "Readed chb14_04.edf\n",
      "Readed chb14_06.edf\n",
      "Readed chb14_11.edf\n",
      "Readed chb14_17.edf\n",
      "Readed chb14_18.edf\n",
      "Readed chb14_27.edf\n",
      "---------------------------------------------- Patient: chb15 ----------------------------------------------------\n",
      "Readed chb15_06.edf\n",
      "Readed chb15_10.edf\n",
      "Readed chb15_15.edf\n",
      "Readed chb15_17.edf\n",
      "Readed chb15_20.edf\n",
      "Readed chb15_22.edf\n",
      "Readed chb15_28.edf\n",
      "Readed chb15_31.edf\n",
      "Readed chb15_40.edf\n",
      "Readed chb15_46.edf\n",
      "Readed chb15_49.edf\n",
      "Readed chb15_52.edf\n",
      "Readed chb15_54.edf\n",
      "Readed chb15_62.edf\n",
      "---------------------------------------------- Patient: chb16 ----------------------------------------------------\n",
      "Readed chb16_10.edf\n",
      "Readed chb16_11.edf\n",
      "Readed chb16_14.edf\n",
      "Readed chb16_16.edf\n",
      "Readed chb16_17.edf\n",
      "Readed chb16_18.edf\n",
      "---------------------------------------------- Patient: chb17 ----------------------------------------------------\n",
      "Readed chb17a_03.edf\n",
      "Readed chb17a_04.edf\n",
      "Readed chb17b_63.edf\n",
      "---------------------------------------------- Patient: chb18 ----------------------------------------------------\n",
      "Readed chb18_29.edf\n",
      "Readed chb18_30.edf\n",
      "Readed chb18_31.edf\n",
      "Readed chb18_32.edf\n",
      "Readed chb18_35.edf\n",
      "Readed chb18_36.edf\n",
      "---------------------------------------------- Patient: chb19 ----------------------------------------------------\n",
      "Readed chb19_28.edf\n",
      "Readed chb19_29.edf\n",
      "Readed chb19_30.edf\n",
      "---------------------------------------------- Patient: chb20 ----------------------------------------------------\n",
      "Readed chb20_12.edf\n",
      "Readed chb20_13.edf\n",
      "Readed chb20_14.edf\n",
      "Readed chb20_15.edf\n",
      "Readed chb20_16.edf\n",
      "Readed chb20_68.edf\n",
      "---------------------------------------------- Patient: chb21 ----------------------------------------------------\n",
      "Readed chb21_19.edf\n",
      "Readed chb21_20.edf\n",
      "Readed chb21_21.edf\n",
      "Readed chb21_22.edf\n",
      "---------------------------------------------- Patient: chb22 ----------------------------------------------------\n",
      "Readed chb22_20.edf\n",
      "Readed chb22_25.edf\n",
      "Readed chb22_38.edf\n",
      "---------------------------------------------- Patient: chb23 ----------------------------------------------------\n",
      "Readed chb23_06.edf\n",
      "Readed chb23_08.edf\n",
      "Readed chb23_09.edf\n",
      "---------------------------------------------- Patient: chb24 ----------------------------------------------------\n",
      "Readed chb24_01.edf\n",
      "Readed chb24_03.edf\n",
      "Readed chb24_04.edf\n",
      "Readed chb24_06.edf\n",
      "Readed chb24_07.edf\n",
      "Readed chb24_09.edf\n",
      "Readed chb24_11.edf\n",
      "Readed chb24_13.edf\n",
      "Readed chb24_14.edf\n",
      "Readed chb24_15.edf\n",
      "Readed chb24_17.edf\n",
      "Readed chb24_21.edf\n"
     ]
    }
   ],
   "source": [
    "timeW = 2\n",
    "decimationCoeff = 2\n",
    "\n",
    "for patient in patients:\n",
    "    print('---------------------------------------------- Patient: ' + patient + ' ----------------------------------------------------')\n",
    "    fdir = dbdir + '\\\\' + patient\n",
    "    os.chdir(fdir)\n",
    "    annotation = glob.glob('*txt')\n",
    "    \n",
    "    registers, channel_index = read_annotations(annotation[0])\n",
    "\n",
    "    nchannels = len(channel_index)\n",
    "    selected_channels_lof = []\n",
    "\n",
    "    dataframe = pd.DataFrame()\n",
    "    for key, value in registers.items():\n",
    "\n",
    "        # Signal reading: only if is a seizure file\n",
    "        if key in seizure_files:\n",
    "            signals, originalfs, time = read_data(key, value.channels)\n",
    "            # Decimation\n",
    "            signals = signal.decimate(signals, decimationCoeff)\n",
    "            fs = originalfs//decimationCoeff\n",
    "\n",
    "            # Truncate to generate time windows\n",
    "            signals_trunc, time, nw, N = trunc(signals, timeW, fs)\n",
    "            samples = signals_trunc.shape[1]\n",
    "\n",
    "            print(\"Readed \" + key)\n",
    "\n",
    "            # Seizure vector creation\n",
    "            seizure = zeros(samples)\n",
    "\n",
    "\n",
    "            for n in range (len(value.seizures)):\n",
    "                start = value.seizures[n][0]*fs\n",
    "                end = value.seizures[n][1]*fs\n",
    "                seizure[start:end] = np.ones(end-start)\n",
    "\n",
    "            seizureW = np.reshape(seizure, [nw, N])\n",
    "            seizureW = (sum(seizureW, 1) > N//2)\n",
    "\n",
    "            selected_signals, selected_channels = select_best_signals2(signals_trunc, nw, N, seizureW, nchannels, channel_index)\n",
    "            selected_channels_lof.append(selected_channels)\n",
    "\n",
    "            # Create the csv file where the significance order of the selected channels is going to be stored\n",
    "            os.chdir(datasetdir)\n",
    "            f = open(patient + '_channel_order.csv', 'w+')\n",
    "            writer=csv.writer(f)\n",
    "            writer.writerow(list(range(nchannels)))\n",
    "            for item in selected_channels_lof:\n",
    "                writer.writerow(item)\n",
    "            f.close()\n",
    "            os.chdir(fdir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
