{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyedflib\n",
    "import numpy as np\n",
    "from pylab import *\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "import seaborn\n",
    "import glob, os\n",
    "from collections import OrderedDict\n",
    "from scipy.stats import *\n",
    "import csv\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing, Holt\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = os.getcwd()\n",
    "# Put here the directory of the CHBMIT DATABASE\n",
    "dbdir = r\"F:\\Master\\TFM\\chb-mit-scalp-eeg-database-1.0.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Register:\n",
    "    \n",
    "    def __init__(self, name, fs, nseizures):\n",
    "        self.name = name\n",
    "        self.fs = fs\n",
    "        self.nseizures = nseizures\n",
    "        self.seizures = []\n",
    "        self.channels = []\n",
    "            \n",
    "    def addSeizure (self, start, end):\n",
    "        seizure = [start, end]\n",
    "        self.seizures.append(seizure)\n",
    "        \n",
    "    def addCh (self, channels):\n",
    "        self.channels = channels\n",
    "\n",
    "def read_data(filename, channels=[]):\n",
    "    f = pyedflib.EdfReader(filename)\n",
    "    if len(channels) == 0:\n",
    "        channels = f.getSignalLabels()\n",
    "\n",
    "    channel_names = f.getSignalLabels()\n",
    "    fs = f.getSampleFrequencies()\n",
    "\n",
    "    data = np.zeros((len(channels), f.getNSamples()[0]))\n",
    "    for i, channel in enumerate(channels):\n",
    "        data[i, :] = f.readSignal(channel_names.index(channel))\n",
    "        \n",
    "    time = np.linspace(0, data.shape[1]/fs[0], data.shape[1])\n",
    "    f._close()\n",
    "    return data, fs[0], time\n",
    "\n",
    "def trunc(data, timeW, fs):\n",
    "    samples = data.shape[1]\n",
    "    timeW = 2\n",
    "    N = timeW*fs\n",
    "    nw = int(samples//N)\n",
    "\n",
    "    data = data [:, 0:nw*N]\n",
    "    time = np.linspace(0, data.shape[1]/fs, data.shape[1])\n",
    "    return data, time, nw, N\n",
    "\n",
    "def calc_variances_entropys(signals, nw, N):\n",
    "    variances = np.zeros([signals.shape[0], nw])\n",
    "    entropys = np.zeros([signals.shape[0], nw])\n",
    "    for channel, signal in enumerate(signals):\n",
    "        signal = np.reshape(signal, [nw, N])\n",
    "        variances[channel, :] = np.var(signal, 1)\n",
    "        for n, s in enumerate(signal):\n",
    "            pd_series = pd.Series(s)\n",
    "            counts = pd_series.value_counts()\n",
    "            entropys[channel, n] = entropy(counts, base = 2)\n",
    "    return variances, entropys\n",
    "\n",
    "\n",
    "\n",
    "def select_best_signals(signals_trunc, nw, N, seizureW, nchannels, channel_index):\n",
    "    variances, entropys = calc_variances_entropys(signals_trunc, nw, N)\n",
    "    \n",
    "    ictal_index = where(seizureW == 1)\n",
    "    \n",
    "    product_var_ent = float32(variances[:, ictal_index[0][0]:ictal_index[0][-1]+1] * entropys[:, ictal_index[0][0]:ictal_index[0][-1]+1])\n",
    "    mean_product = mean(product_var_ent, 1)\n",
    "    \n",
    "    dictionary = dict(zip(channel_index.keys(), mean_product))\n",
    "    sorted_dict = {k: v for k, v in sorted(dictionary.items(), key=lambda item: item[1], reverse=True)}\n",
    "    \n",
    "    # Extract first 4 and create the valid signals\n",
    "    significant_channels = list(sorted_dict.keys())[0:nchannels]\n",
    "    significant_signals = zeros([len(significant_channels), signals_trunc.shape[1]])\n",
    "    for i, key in enumerate(significant_channels):\n",
    "        significant_signals[i, :] = signals_trunc[channel_index[key], :]\n",
    "        \n",
    "    return significant_signals, significant_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frec2sample_range(fi, fo, fs, N):\n",
    "    si = max(1,floor(fi*N/fs))\n",
    "    so = ceil(fo*N/fs)\n",
    "    return int(si), int(so)\n",
    "\n",
    "def band_energy(fft, fs):\n",
    "    N = len(fft)\n",
    "    # Energia total\n",
    "    et = sum(fft)\n",
    "    dsi, dso = frec2sample_range(0.5, 4, fs, N)\n",
    "    d = sum(fft[dsi:dso])\n",
    "    tsi, tso = frec2sample_range(4, 7, fs, N)\n",
    "    t = sum(fft[tsi:tso])\n",
    "    asi, aso = frec2sample_range(7, 13, fs, N)\n",
    "    a = sum(fft[asi:aso])\n",
    "    bsi, bso = frec2sample_range(13, 30, fs, N)\n",
    "    b = sum(fft[bsi:bso])\n",
    "    gsi, gso = frec2sample_range(30, 50, fs, N)\n",
    "    g = sum(fft[gsi:gso])\n",
    "    return et, d, t, a, b, g\n",
    "\n",
    "def psd(signal):\n",
    "    X = fft(signal)\n",
    "    Px = real(X*conj(X))\n",
    "    return Px\n",
    "\n",
    "def exponential_smooth(timeseries, alpha=0.3):\n",
    "    model = SimpleExpSmoothing(timeseries)\n",
    "    fit = model.fit(smoothing_level=alpha)\n",
    "    return fit.fittedvalues\n",
    "\n",
    "def spectral_centroid(nf, ps):\n",
    "    return sum(nf * ps)\n",
    "\n",
    "def variational_coeff(nf, ps, sc):\n",
    "    return sum( (((nf - sc))**2) * ps) / sum(ps)\n",
    "\n",
    "def spectral_skew(nf, ps, sc, vc):\n",
    "    return sum( ((nf - sc)/vc)**3 * ps) / sum(ps)\n",
    "    \n",
    "\n",
    "def channel_processing(channel_matrix, fs):\n",
    "    \n",
    "        ninstances = channel_matrix.shape[0]\n",
    "        et = zeros(ninstances)\n",
    "        d = zeros(ninstances)\n",
    "        t = zeros(ninstances)\n",
    "        a = zeros(ninstances)\n",
    "        b = zeros(ninstances)\n",
    "        g = zeros(ninstances)\n",
    "\n",
    "        meanv = zeros(ninstances)\n",
    "        variancev = zeros(ninstances)\n",
    "        skewnessv = zeros(ninstances)\n",
    "        kurtosisv = zeros(ninstances)\n",
    "        stdv = zeros(ninstances)\n",
    "        zcrossingsv = zeros(ninstances)\n",
    "        p2pv = zeros(ninstances)\n",
    "\n",
    "        spectralCentroid = zeros(ninstances)\n",
    "        variationalCoeff = zeros(ninstances)\n",
    "        spectralSkew = zeros(ninstances)\n",
    "\n",
    "        #df = pd.DataFrame()\n",
    "        features = ['mean', 'variance', 'skewness', 'kurtosis', 'std', 'zero_crossings', 'peak2peak',\n",
    "                    'total_energy', 'delta', 'theta', 'alpha', 'beta', 'gamma',\n",
    "                    'spectral_centroid', 'variatonial_coeff', 'spectral_skew']\n",
    "\n",
    "        for index, row in enumerate(channel_matrix):\n",
    "            try:\n",
    "                meanv[index] = mean(row)\n",
    "                variancev[index] = var(row)\n",
    "                skewnessv[index] = skew(row)\n",
    "                kurtosisv[index] = kurtosis(row)\n",
    "                stdv[index] = std(row)\n",
    "                zcrossingsv[index] = len(np.where(np.diff(np.sign(row)))[0])\n",
    "                p2pv[index] = max(row)-min(row)\n",
    "\n",
    "            except ZeroDivisionError:\n",
    "                meanv[index] = 0.001\n",
    "                variancev[index] = 0.001\n",
    "                skewnessv[index] = 0.001\n",
    "                kurtosisv[index] = 0.001\n",
    "                stdv[index] = 0.001\n",
    "                zcrossingsv[index] = 0.001\n",
    "                p2pv[index] = 0.001\n",
    "\n",
    "            Px = psd(row)\n",
    "            et[index], d[index], t[index], a[index], b[index], g[index] = band_energy(Px, fs)\n",
    "\n",
    "            p_spectrum = Px[:len(Px)//2]/sum(Px[:len(Px)//2])\n",
    "            normalized_f = linspace(0, 1, len(Px)//2)\n",
    "            spectralCentroid[index] = spectral_centroid(normalized_f, p_spectrum)\n",
    "            variationalCoeff[index] = variational_coeff(normalized_f, p_spectrum, spectralCentroid[index])\n",
    "            spectralSkew[index] = spectral_skew(normalized_f, p_spectrum, spectralCentroid[index], variationalCoeff[index])\n",
    "\n",
    "\n",
    "        data = [exponential_smooth( (meanv)), exponential_smooth( (variancev)), exponential_smooth( (skewnessv)),\n",
    "                exponential_smooth( (kurtosisv)), exponential_smooth( (stdv)),exponential_smooth( (zcrossingsv)),exponential_smooth( (p2pv)),\n",
    "                exponential_smooth( (et)), exponential_smooth( (d)), exponential_smooth( (t)),\n",
    "                exponential_smooth( (a)), exponential_smooth( (b)),exponential_smooth( (g)),\n",
    "                exponential_smooth( (spectralCentroid)),exponential_smooth( (variationalCoeff)), exponential_smooth( (spectralSkew))\n",
    "        ]\n",
    "\n",
    "        data = np.array(data).transpose()\n",
    "        df = pd.DataFrame(data, columns = features)\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 2,  3,  4,  5],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 6,  7,  8,  9],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [10, 11, 12, 13],\n",
       "       [12, 13, 14, 15],\n",
       "       [14, 15, 16, 17],\n",
       "       [16, 17, 18, 19],\n",
       "       [18, 19, 20, 21],\n",
       "       [20, 21, 22, 23],\n",
       "       [22, 23, 24, 25],\n",
       "       [24, 25, 26, 27],\n",
       "       [26, 27, 28, 29],\n",
       "       [28, 29, 30, 31]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 4\n",
    "A = np.array(range(32))\n",
    "newA = skimage.util.view_as_windows(A, N, N//2)\n",
    "newA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15],\n",
       "       [16, 17, 18, 19],\n",
       "       [20, 21, 22, 23],\n",
       "       [24, 25, 26, 27],\n",
       "       [28, 29, 30, 31]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newnewA = np.reshape(A, [8, 4])\n",
    "newnewA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_annotations(annotation):\n",
    "    with open(annotation) as f:\n",
    "        registers = {}\n",
    "        channels = []\n",
    "        for line in f:\n",
    "            if (\"Data Sampling Rate\" in line):\n",
    "                line = line.split()\n",
    "                fs = int(line[3])            \n",
    "            if (\"Channel \" in line):\n",
    "                line = line.split()\n",
    "                channels.append(line[2])\n",
    "            if (\"Channels changed\" in line):\n",
    "                channels = []\n",
    "            elif (\"File Name\" in line):\n",
    "                name = line.split()[2]\n",
    "                while True:\n",
    "                    newLine = f.readline()\n",
    "                    if (\"Number of Seizures\" in newLine):\n",
    "                        nseizures = int(newLine.split()[5])\n",
    "                        register = Register(name, fs, nseizures)\n",
    "                        if nseizures > 0:\n",
    "                            for i in range(nseizures):\n",
    "                                line1 = f.readline().split()\n",
    "                                line2 = f.readline().split()\n",
    "                                if (line1[3] == \"Time:\"):\n",
    "                                    start = int(line1[4])\n",
    "                                    end = int(line2[4])\n",
    "                                else:\n",
    "                                    start = int(line1[3])\n",
    "                                    end = int(line2[3])\n",
    "                                register.addSeizure(start, end)\n",
    "\n",
    "                        register.addCh(list(channels))\n",
    "                        registers[name] = register\n",
    "                        break\n",
    "\n",
    "    channel_index = dict(zip(register.channels, list(np.arange(len(register.channels)))))\n",
    "    return registers, channel_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset for only one patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = 'chb08'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(dbdir + '\\RECORDS-WITH-SEIZURES', 'r', encoding = 'utf-8')\n",
    "seizure_files = f.read().split('\\n')\n",
    "seizure_files = list(map(lambda string: string[6:], seizure_files))\n",
    "f.close()\n",
    "\n",
    "fdir = dbdir + '\\\\' + patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(fdir)\n",
    "annotation = glob.glob('*txt')\n",
    "\n",
    "registers, channel_index = read_annotations(annotation[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FP1-F7': 0,\n",
       " 'F7-T7': 1,\n",
       " 'T7-P7': 2,\n",
       " 'P7-O1': 3,\n",
       " 'FP1-F3': 4,\n",
       " 'F3-C3': 5,\n",
       " 'C3-P3': 6,\n",
       " 'P3-O1': 7,\n",
       " 'FP2-F4': 8,\n",
       " 'F4-C4': 9,\n",
       " 'C4-P4': 10,\n",
       " 'P4-O2': 11,\n",
       " 'FP2-F8': 12,\n",
       " 'F8-T8': 13,\n",
       " 'T8-P8': 22,\n",
       " 'P8-O2': 15,\n",
       " 'FZ-CZ': 16,\n",
       " 'CZ-PZ': 17,\n",
       " 'P7-T7': 18,\n",
       " 'T7-FT9': 19,\n",
       " 'FT9-FT10': 20,\n",
       " 'FT10-T8': 21}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Readed chb08_02.edf\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-3ad0080cda7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[0mseizure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0mnewSignal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview_as_windows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[0mseizureW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseizureW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "# Select window duration in seconds\n",
    "timeW = 2\n",
    "overlapping = 0.5\n",
    "nchannels = len(channel_index)\n",
    "decimationCoeff = 2\n",
    "fs = registers['chb08_02.edf'].fs\n",
    "\n",
    "selected_channels_lof = []\n",
    "\n",
    "dataframe = pd.DataFrame()\n",
    "for key, value in registers.items():\n",
    "    \n",
    "    # Signal reading: only if is a seizure file\n",
    "    if key in seizure_files:\n",
    "        \n",
    "        # Signal reading\n",
    "        signals, fs, time = read_data(key, value.channels)\n",
    "        # Decimation\n",
    "        signals = signal.decimate(signals, decimationCoeff)\n",
    "        fs = fs//decimationCoeff\n",
    "\n",
    "        # Truncate to generate time windows\n",
    "        signals_trunc, time, nw, N = trunc(signals, timeW, fs)\n",
    "        nw = int(nw/overlapping)\n",
    "        samples = signals_trunc.shape[1]\n",
    "\n",
    "        print(\"Readed \" + key)\n",
    "\n",
    "        # Seizure vector creation\n",
    "        seizure = zeros(samples)\n",
    "        if (len(value.seizures) > 0):\n",
    "            for n in range (len(value.seizures)):\n",
    "                start = value.seizures[n][0]*fs\n",
    "                end = value.seizures[n][1]*fs\n",
    "                seizure[start:end] = np.ones(end-start)\n",
    "\n",
    "            newSignal = skimage.util.view_as_windows(s, N, N//2)\n",
    "            seizureW = (sum(seizureW, 1) > N//2)\n",
    "\n",
    "            selected_signals, selected_channels = select_best_signals(signals_trunc, nw, N, seizureW, nchannels, channel_index)\n",
    "            selected_channels_lof.append(selected_channels)\n",
    "\n",
    "            # Create list for feature names\n",
    "            features = []\n",
    "            for i in range(N):\n",
    "                features.append(\"sample\" + str(i+1))\n",
    "\n",
    "            # Create register dataframe\n",
    "            auxdf = pd.DataFrame()\n",
    "            for channel, s in enumerate(selected_signals):\n",
    "                print(s.shape)\n",
    "                newSignal = skimage.util.view_as_windows(s, N, N//2)\n",
    "                newdf = channel_processing(newSignal, fs)\n",
    "                newdf['channel'] = pd.Series( [selected_channels[channel]]*nw, index = newdf.index)\n",
    "                newdf['seizure'] = pd.Series( seizureW, index = newdf.index)\n",
    "                auxdf = auxdf.append(newdf, ignore_index=True)\n",
    "                print(\"Rows created for \" + selected_channels[channel] + \" channel\")\n",
    "\n",
    "            # Add to the patient dataframe\n",
    "            dataframe = dataframe.append(auxdf, ignore_index=True)\n",
    "            print(\"Rows created for \" + key)\n",
    "\n",
    "os.chdir(basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the datase and the csv with the list of significant channels\n",
    "datasetdir = basedir + '\\Datasets'\n",
    "dataframe.to_hdf(datasetdir + '\\\\' + patient + 'features' + '.h5', key = 'fullpatient', mode = 'w', format = 'table')\n",
    "\n",
    "# Create the csv file where the significance order of the selected channels is going to be stored\n",
    "os.chdir(datasetdir)\n",
    "f = open(patient + '_channel_order.csv', 'w+')\n",
    "writer=csv.writer(f)\n",
    "writer.writerow(list(range(nchannels)))\n",
    "for item in selected_channels_lof:\n",
    "    writer.writerow(item)\n",
    "f.close()\n",
    "os.chdir(basedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset creation for all the patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = os.getcwd()\n",
    "datasetdir = basedir + '\\Datasets'\n",
    "\n",
    "# Put here the directory of the CHBMIT DATABASE\n",
    "dbdir = r\"F:\\Master\\TFM\\chb-mit-scalp-eeg-database-1.0.0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chb01',\n",
       " 'chb02',\n",
       " 'chb03',\n",
       " 'chb05',\n",
       " 'chb06',\n",
       " 'chb07',\n",
       " 'chb08',\n",
       " 'chb09',\n",
       " 'chb10',\n",
       " 'chb11']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(dbdir)\n",
    "patients = [name for name in os.listdir(\".\") if os.path.isdir(name)]\n",
    "patients[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(dbdir + '\\RECORDS-WITH-SEIZURES', 'r', encoding = 'utf-8')\n",
    "seizure_files = f.read().split('\\n')\n",
    "seizure_files = list(map(lambda string: string[6:], seizure_files))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------- Patient: chb01 ----------------------------------------------------\n",
      "Readed chb01_03.edf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mario\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\holtwinters.py:731: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  loc = initial_p >= ub\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows created for chb01_03.edf\n",
      "Readed chb01_04.edf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mario\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\holtwinters.py:731: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  loc = initial_p >= ub\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows created for chb01_04.edf\n",
      "Readed chb01_15.edf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mario\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\holtwinters.py:744: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows created for chb01_15.edf\n",
      "Readed chb01_16.edf\n",
      "Rows created for chb01_16.edf\n",
      "Readed chb01_18.edf\n",
      "Rows created for chb01_18.edf\n",
      "Readed chb01_21.edf\n",
      "Rows created for chb01_21.edf\n",
      "Readed chb01_26.edf\n",
      "Rows created for chb01_26.edf\n",
      "---------------------------------------------- Patient: chb02 ----------------------------------------------------\n",
      "Readed chb02_16.edf\n",
      "Rows created for chb02_16.edf\n",
      "Readed chb02_19.edf\n",
      "Rows created for chb02_19.edf\n",
      "---------------------------------------------- Patient: chb03 ----------------------------------------------------\n",
      "Readed chb03_01.edf\n",
      "Rows created for chb03_01.edf\n",
      "Readed chb03_02.edf\n",
      "Rows created for chb03_02.edf\n",
      "Readed chb03_03.edf\n",
      "Rows created for chb03_03.edf\n",
      "Readed chb03_04.edf\n",
      "Rows created for chb03_04.edf\n",
      "Readed chb03_34.edf\n",
      "Rows created for chb03_34.edf\n",
      "Readed chb03_35.edf\n",
      "Rows created for chb03_35.edf\n",
      "Readed chb03_36.edf\n",
      "Rows created for chb03_36.edf\n",
      "---------------------------------------------- Patient: chb05 ----------------------------------------------------\n",
      "Readed chb05_06.edf\n",
      "Rows created for chb05_06.edf\n",
      "Readed chb05_13.edf\n",
      "Rows created for chb05_13.edf\n",
      "Readed chb05_16.edf\n",
      "Rows created for chb05_16.edf\n",
      "Readed chb05_17.edf\n",
      "Rows created for chb05_17.edf\n",
      "Readed chb05_22.edf\n",
      "Rows created for chb05_22.edf\n",
      "---------------------------------------------- Patient: chb06 ----------------------------------------------------\n",
      "Readed chb06_01.edf\n",
      "Rows created for chb06_01.edf\n",
      "Readed chb06_04.edf\n",
      "Rows created for chb06_04.edf\n",
      "Readed chb06_09.edf\n",
      "Rows created for chb06_09.edf\n",
      "Readed chb06_10.edf\n",
      "Rows created for chb06_10.edf\n",
      "Readed chb06_13.edf\n",
      "Rows created for chb06_13.edf\n",
      "Readed chb06_18.edf\n",
      "Rows created for chb06_18.edf\n",
      "Readed chb06_24.edf\n",
      "Rows created for chb06_24.edf\n",
      "---------------------------------------------- Patient: chb07 ----------------------------------------------------\n",
      "Readed chb07_12.edf\n",
      "Rows created for chb07_12.edf\n",
      "Readed chb07_13.edf\n",
      "Rows created for chb07_13.edf\n",
      "Readed chb07_19.edf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mario\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: RuntimeWarning: divide by zero encountered in true_divide\n",
      "C:\\Users\\Mario\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\Mario\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:39: RuntimeWarning: invalid value encountered in multiply\n",
      "C:\\Users\\Mario\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\holtwinters.py:744: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows created for chb07_19.edf\n",
      "---------------------------------------------- Patient: chb08 ----------------------------------------------------\n",
      "Readed chb08_02.edf\n",
      "Rows created for chb08_02.edf\n",
      "Readed chb08_05.edf\n",
      "Rows created for chb08_05.edf\n",
      "Readed chb08_11.edf\n",
      "Rows created for chb08_11.edf\n",
      "Readed chb08_13.edf\n",
      "Rows created for chb08_13.edf\n",
      "Readed chb08_21.edf\n",
      "Rows created for chb08_21.edf\n",
      "---------------------------------------------- Patient: chb09 ----------------------------------------------------\n",
      "Readed chb09_06.edf\n",
      "Rows created for chb09_06.edf\n",
      "Readed chb09_08.edf\n",
      "Rows created for chb09_08.edf\n",
      "Readed chb09_19.edf\n",
      "Rows created for chb09_19.edf\n",
      "---------------------------------------------- Patient: chb10 ----------------------------------------------------\n",
      "Readed chb10_12.edf\n",
      "Rows created for chb10_12.edf\n",
      "Readed chb10_20.edf\n",
      "Rows created for chb10_20.edf\n",
      "Readed chb10_27.edf\n",
      "Rows created for chb10_27.edf\n",
      "Readed chb10_30.edf\n",
      "Rows created for chb10_30.edf\n",
      "Readed chb10_31.edf\n",
      "Rows created for chb10_31.edf\n",
      "Readed chb10_38.edf\n",
      "Rows created for chb10_38.edf\n",
      "Readed chb10_89.edf\n",
      "Rows created for chb10_89.edf\n",
      "---------------------------------------------- Patient: chb11 ----------------------------------------------------\n",
      "Readed chb11_82.edf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mario\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\holtwinters.py:956: RuntimeWarning: divide by zero encountered in log\n",
      "  aic = self.nobs * np.log(sse / self.nobs) + k * 2\n",
      "C:\\Users\\Mario\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\holtwinters.py:962: RuntimeWarning: divide by zero encountered in log\n",
      "  bic = self.nobs * np.log(sse / self.nobs) + k * np.log(self.nobs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows created for chb11_82.edf\n",
      "Readed chb11_92.edf\n",
      "Rows created for chb11_92.edf\n",
      "Readed chb11_99.edf\n",
      "Rows created for chb11_99.edf\n",
      "---------------------------------------------- Patient: chb12 ----------------------------------------------------\n",
      "Readed chb12_06.edf\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-ccdb59f88aae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mseizureW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseizureW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             \u001b[0mselected_signals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mselected_channels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_best_signals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignals_trunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseizureW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnchannels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m             \u001b[0mselected_channels_lof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mselected_channels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-f64614c8f576>\u001b[0m in \u001b[0;36mselect_best_signals\u001b[1;34m(signals_trunc, nw, N, seizureW, nchannels, channel_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mselect_best_signals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignals_trunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseizureW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnchannels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchannel_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[0mvariances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalc_variances_entropys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignals_trunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mictal_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseizureW\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-f64614c8f576>\u001b[0m in \u001b[0;36mcalc_variances_entropys\u001b[1;34m(signals, nw, N)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mpd_series\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m             \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd_series\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m             \u001b[0mentropys\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchannel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mvariances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36mvalue_counts\u001b[1;34m(self, normalize, sort, ascending, bins, dropna)\u001b[0m\n\u001b[0;32m   1242\u001b[0m             \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m             \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1244\u001b[1;33m             \u001b[0mdropna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1245\u001b[0m         )\n\u001b[0;32m   1246\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mvalue_counts\u001b[1;34m(values, sort, ascending, normalize, bins, dropna)\u001b[0m\n\u001b[0;32m    721\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 723\u001b[1;33m             \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_value_counts_arraylike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropna\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    724\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36m_value_counts_arraylike\u001b[1;34m(values, dropna)\u001b[0m\n\u001b[0;32m    765\u001b[0m         \u001b[1;31m# TODO: handle uint8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"value_count_{ndtype}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m         \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropna\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_func_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.value_count_float64\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_func_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.value_count_float64\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     14\u001b[0m ]\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;33m@\u001b[0m\u001b[0mset_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'numpy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \"\"\"Convert the input to an array.\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "timeW = 2\n",
    "overlapping = 0.5\n",
    "decimationCoeff = 2\n",
    "\n",
    "for patient in patients:\n",
    "    print('---------------------------------------------- Patient: ' + patient + ' ----------------------------------------------------')\n",
    "    fdir = dbdir + '\\\\' + patient\n",
    "    os.chdir(fdir)\n",
    "    annotation = glob.glob('*txt')\n",
    "    \n",
    "    registers, channel_index = read_annotations(annotation[0])\n",
    "\n",
    "    nchannels = len(channel_index)\n",
    "    selected_channels_lof = []\n",
    "\n",
    "    dataframe = pd.DataFrame()\n",
    "    for key, value in registers.items():\n",
    "\n",
    "        # Signal reading: only if is a seizure file\n",
    "        if key in seizure_files:\n",
    "            signals, originalfs, time = read_data(key, value.channels)\n",
    "            # Decimation\n",
    "            signals = signal.decimate(signals, decimationCoeff)\n",
    "            fs = originalfs//decimationCoeff\n",
    "\n",
    "            # Truncate to generate time windows\n",
    "            signals_trunc, time, nw, N = trunc(signals, timeW, fs)\n",
    "            nw = int(nw/overlapping)\n",
    "            samples = signals_trunc.shape[1]\n",
    "\n",
    "            print(\"Readed \" + key)\n",
    "\n",
    "            # Seizure vector creation\n",
    "            seizure = zeros(samples)\n",
    "\n",
    "\n",
    "            for n in range (len(value.seizures)):\n",
    "                start = value.seizures[n][0]*fs\n",
    "                end = value.seizures[n][1]*fs\n",
    "                seizure[start:end] = np.ones(end-start)\n",
    "\n",
    "            seizureW = np.reshape(seizure, [nw, N])\n",
    "            seizureW = (sum(seizureW, 1) > N//2)\n",
    "\n",
    "            selected_signals, selected_channels = select_best_signals(signals_trunc, nw, N, seizureW, nchannels, channel_index)\n",
    "            selected_channels_lof.append(selected_channels)\n",
    "\n",
    "            # Create register dataframe\n",
    "            auxdf = pd.DataFrame()\n",
    "            for channel, s in enumerate(selected_signals):\n",
    "                newSignal = skimage.util.view_as_windows(s, N, N//2)\n",
    "                newdf = channel_processing(newSignal, fs)\n",
    "                newdf['channel'] = pd.Series( [selected_channels[channel]]*nw, index = newdf.index)\n",
    "                newdf['seizure'] = pd.Series( seizureW, index = newdf.index)\n",
    "                auxdf = auxdf.append(newdf, ignore_index=True)\n",
    "\n",
    "            # Add to the patient dataframe\n",
    "            dataframe = dataframe.append(auxdf, ignore_index=True)\n",
    "            print(\"Rows created for \" + key)\n",
    "            \n",
    "            # Save the datase and the csv with the list of significant channels\n",
    "            dataframe.to_hdf(datasetdir + '\\\\' + patient + 'features' + '.h5', key = 'fullpatient', mode = 'w', format = 'table')\n",
    "\n",
    "            # Create the csv file where the significance order of the selected channels is going to be stored\n",
    "            os.chdir(datasetdir)\n",
    "            f = open(patient + '_channel_order.csv', 'w+')\n",
    "            writer=csv.writer(f)\n",
    "            writer.writerow(list(range(nchannels)))\n",
    "            for item in selected_channels_lof:\n",
    "                writer.writerow(item)\n",
    "            f.close()\n",
    "            os.chdir(fdir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
